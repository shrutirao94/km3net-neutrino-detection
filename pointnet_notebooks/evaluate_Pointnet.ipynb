{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KM3Net:Evaluate_Meshes.ipynb","provenance":[{"file_id":"https://github.com/nikitakaraevv/pointnet/blob/master/nbs/PointNetClass.ipynb","timestamp":1592852121085}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NpvL68OfBEQC"},"source":["# Testing on Unseen Data"]},{"cell_type":"code","metadata":{"id":"TJ47VNF7fmTS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606236783872,"user_tz":-60,"elapsed":97922,"user":{"displayName":"Shruti Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjlnsO6ZJqh75mi4ALesQLq4jofkr4lg9wMx8kckzc=s64","userId":"05348310931573326252"}},"outputId":"d5f9e4b1-64a4-457d-f358-6a0b80379a2c"},"source":["import itertools\n","import math\n","import os\n","!pip install path.py\n","from path import Path\n","import random\n","import numpy as np\n","# import matplotlib.pyplot as plt\n","# import plotly.graph_objects as go\n","# import plotly.express as px\n","# import scipy.spatial.distance\n","# !pip install scikit-plot\n","# import scikitplot as skplt\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","\n","# from sklearn import metrics\n","# from sklearn.metrics import confusion_matrix\n","# from sklearn.metrics import precision_recall_curve\n","# from sklearn.metrics import plot_precision_recall_curve\n","# from sklearn.metrics import average_precision_score\n","# from sklearn.metrics import classification_report\n","# from sklearn.metrics import roc_curve\n","# from sklearn.metrics import roc_auc_score\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","random.seed = 1234"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting path.py\n","  Downloading https://files.pythonhosted.org/packages/8f/04/130b7a538c25693c85c4dee7e25d126ebf5511b1eb7320e64906687b159e/path.py-12.5.0-py3-none-any.whl\n","Collecting path\n","  Downloading https://files.pythonhosted.org/packages/cb/81/b9090d24e60369fd9413b92fcd87e13a37bf43dad3427d35e09915f788ac/path-15.0.0-py3-none-any.whl\n","Installing collected packages: path, path.py\n","Successfully installed path-15.0.0 path.py-12.5.0\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i06OYFNR8fa_","executionInfo":{"status":"ok","timestamp":1606236803168,"user_tz":-60,"elapsed":1104,"user":{"displayName":"Shruti Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjlnsO6ZJqh75mi4ALesQLq4jofkr4lg9wMx8kckzc=s64","userId":"05348310931573326252"}}},"source":["def read_off(file):\n","    if 'OFF' != file.readline().strip():\n","        raise('Not a valid OFF header')\n","        \n","    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n","    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n","    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n","\n","    return verts, faces\n","\n","\n","class PointSampler(object):\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, int)\n","        self.output_size = output_size\n","    \n","    def triangle_area(self, pt1, pt2, pt3):\n","        side_a = np.linalg.norm(pt1 - pt2)\n","        side_b = np.linalg.norm(pt2 - pt3)\n","        side_c = np.linalg.norm(pt3 - pt1)\n","        s = 0.5 * ( side_a + side_b + side_c)\n","        return max(s *\n","                   (s - side_a) * \n","                   (s - side_b) * \n","                   (s - side_c), 0)**0.5\n","\n","    def sample_point(self, pt1, pt2, pt3):\n","        # barycentric coordinates on a triangle\n","        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n","        s, t = sorted([random.random(), random.random()])\n","        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n","        return (f(0), f(1), f(2))\n","        \n","    \n","    def __call__(self, mesh):\n","        verts, faces = mesh\n","        verts = np.array(verts)\n","        areas = np.zeros((len(faces)))\n","\n","        for i in range(len(areas)):\n","            areas[i] = (self.triangle_area(verts[faces[i][0]],\n","                                           verts[faces[i][1]],\n","                                           verts[faces[i][2]]))\n","            \n","        sampled_faces = (random.choices(faces, \n","                                      weights=areas,\n","                                      cum_weights=None,\n","                                      k=self.output_size))\n","        \n","        sampled_points = np.zeros((self.output_size, 3))\n","\n","        for i in range(len(sampled_faces)):\n","            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n","                                                   verts[sampled_faces[i][1]],\n","                                                   verts[sampled_faces[i][2]]))\n","        \n","        return sampled_points\n","\n","\n","class Normalize(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","        \n","        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n","        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n","\n","        return  norm_pointcloud\n","\n","\n","class RandRotation_z(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","\n","        theta = random.random() * 2. * math.pi\n","        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n","                               [ math.sin(theta),  math.cos(theta),    0],\n","                               [0,                             0,      1]])\n","        \n","        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n","        return  rot_pointcloud\n","    \n","class RandomNoise(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","\n","        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n","    \n","        noisy_pointcloud = pointcloud + noise\n","        return  noisy_pointcloud\n","\n","\n","class ToTensor(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","\n","        return torch.from_numpy(pointcloud)\n","\n","\n","def default_transforms():\n","    return transforms.Compose([PointSampler(6550),\n","                               Normalize(),\n","                               RandRotation_z(),\n","                               RandomNoise(),\n","                               ToTensor()])\n","\n","\n","class PointCloudData(Dataset):\n","    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n","        self.root_dir = root_dir\n","        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n","        self.classes = {folder: i for i, folder in enumerate(folders)}\n","        self.transforms = transform if not valid else default_transforms()\n","        self.valid = valid\n","        self.files = []\n","        for category in self.classes.keys():\n","            new_dir = root_dir/Path(category)/folder\n","            for file in os.listdir(new_dir):\n","                if file.endswith('.off'):\n","                    sample = {}\n","                    sample['pcd_path'] = new_dir/file\n","                    sample['category'] = category\n","                    self.files.append(sample)\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __preproc__(self, file):\n","        verts, faces = read_off(file)\n","        if self.transforms:\n","            pointcloud = self.transforms((verts, faces))\n","        return pointcloud\n","\n","    def __getitem__(self, idx):\n","        pcd_path = self.files[idx]['pcd_path']\n","        category = self.files[idx]['category']\n","        with open(pcd_path, 'r') as f:\n","            pointcloud = self.__preproc__(f)\n","        return {'pointcloud': pointcloud, \n","                'category': self.classes[category]}\n","\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","\n","class Tnet(nn.Module):\n","   def __init__(self, k=3):\n","      super().__init__()\n","      self.k=k\n","      self.conv1 = nn.Conv1d(k,64,1)\n","      self.conv2 = nn.Conv1d(64,128,1)\n","      self.conv3 = nn.Conv1d(128,1024,1)\n","\n","      self.fc1 = nn.Linear(1024,512)\n","      self.fc2 = nn.Linear(512,256)\n","      self.fc3 = nn.Linear(256,k*k)\n","\n","      self.bn1 = nn.BatchNorm1d(64)\n","      self.bn2 = nn.BatchNorm1d(128)\n","      self.bn3 = nn.BatchNorm1d(1024)\n","      self.bn4 = nn.BatchNorm1d(512)\n","      self.bn5 = nn.BatchNorm1d(256)\n","       \n","\n","   def forward(self, input):\n","      bs = input.size(0)\n","      # input.shape == (bs,n,3)\n","      xb = F.relu(self.bn1(self.conv1(input)))\n","      xb = F.relu(self.bn2(self.conv2(xb)))\n","      xb = F.relu(self.bn3(self.conv3(xb)))\n","\n","      # pool = nn.MaxPool1d(xb.size(-1))(xb)\n","      pool = nn.AvgPool1d(xb.size(-1))(xb)\n","      flat = nn.Flatten(1)(pool)\n","\n","      xb = F.relu(self.bn4(self.fc1(flat)))\n","      xb = F.relu(self.bn5(self.fc2(xb)))\n","      \n","      #initialize as identity\n","      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n","      if xb.is_cuda:\n","        init=init.cuda()\n","      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n","      return matrix\n","\n","\n","class Transform(nn.Module):\n","   def __init__(self):\n","        super().__init__()\n","        self.input_transform = Tnet(k=3)\n","        self.feature_transform = Tnet(k=64)\n","\n","        self.conv1 = nn.Conv1d(3,64,1)\n","        self.conv2 = nn.Conv1d(64,128,1)\n","        self.conv3 = nn.Conv1d(128,1024,1)\n","       \n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(1024)\n","       \n","   def forward(self, input):\n","        matrix3x3 = self.input_transform(input)\n","        # batch matrix multiplication\n","        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n","        xb = F.relu(self.bn1(self.conv1(xb)))\n","\n","        matrix64x64 = self.feature_transform(xb)\n","\n","        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n","\n","        xb = F.relu(self.bn2(self.conv2(xb)))\n","        xb = self.bn3(self.conv3(xb))\n","        # xb = nn.MaxPool1d(xb.size(-1))(xb)\n","        xb = nn.AvgPool1d(xb.size(-1))(xb)\n","        output = nn.Flatten(1)(xb)\n","\n","        return output, matrix3x3, matrix64x64\n","\n","class PointNet(nn.Module):\n","    def __init__(self, classes = 2):\n","        super().__init__()\n","        self.transform = Transform()\n","        self.fc1 = nn.Linear(1024, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, classes)\n","        \n","\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.bn2 = nn.BatchNorm1d(256)\n","\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.logsigmoid = nn.LogSigmoid()\n","\n","    def forward(self, input):\n","        xb, matrix3x3, matrix64x64 = self.transform(input)\n","        xb = F.relu(self.bn1(self.fc1(xb)))\n","        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n","        output = self.fc3(xb)\n","\n","        # return output, matrix3x3, matrix64x64\n","        return self.logsigmoid(output), matrix3x3, matrix64x64\n","\n","\n","def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.001):\n","    criterion = torch.nn.NLLLoss()\n","    bs=outputs.size(0)\n","    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n","    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n","    if outputs.is_cuda:\n","        id3x3=id3x3.cuda()\n","        id64x64=id64x64.cuda()\n","    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n","    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n","\n","    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5Q1kjGXGH7j","executionInfo":{"status":"ok","timestamp":1606236807414,"user_tz":-60,"elapsed":472,"user":{"displayName":"Shruti Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjlnsO6ZJqh75mi4ALesQLq4jofkr4lg9wMx8kckzc=s64","userId":"05348310931573326252"}}},"source":["class UnseenPointCloudData(Dataset):\n","    def __init__(self, root_dir, transform=default_transforms()):\n","        self.files = []\n","        self.root_dir = root_dir\n","        self.transforms = transform \n","       \n","        for file in os.listdir(root_dir):\n","           if file.endswith('.off'):\n","              sample = {}\n","              sample['pcd_path'] = root_dir/file\n","              self.files.append(sample)\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __preproc__(self, file):\n","        verts, faces = read_off(file)\n","\n","        if self.transforms:\n","            pointcloud = self.transforms((verts, faces))\n","\n","        return pointcloud\n","\n","    def __getitem__(self, idx):\n","        pcd_path = self.files[idx]['pcd_path']\n","        print(\"PCD_PATH: \", pcd_path)\n","\n","        with open(pcd_path, 'r') as f:\n","            pointcloud = self.__preproc__(f)\n","\n","        return {'pointcloud': pointcloud}\n","\n","\n","def evaluate_unseen_data(unseen_loader):\n","    pointnet.to(device)\n","    predictions = []\n","    to_save = []\n","\n","    with torch.no_grad():\n","      for data in unseen_loader:\n","        inputs = data['pointcloud'].to(device).float()\n","        outputs, __, __ = pointnet(inputs.transpose(1,2))\n","        _, predicted = torch.max(outputs.data, 1)\n","        print(\"Predicted Label:  \", predicted.item())\n","        print(\"------\")\n","        predictions.append(predicted.item())\n","\n","      return predictions\n","\n","\n","\n","def hard_voting(results):\n","    hard_votes = []\n","    zipped_results = zip(results[0], results[1], results[2])\n","    for val in zipped_results:\n","        vals, counts = np.unique(val, return_counts=True)\n","        idx = np.argmax(counts)\n","        hard_votes.append(vals[idx])\n","\n","    return hard_votes\n","\n","def soft_voting(results):\n","    THRESHOLD = .90\n","    soft_votes = []\n","    zipped_probabilities = zip(results[0],\n","                               results[1],\n","                               results[2])\n","    \n","    for item in zipped_probabilities:\n","        average = sum(item)/3\n","        soft_votes.append(average)\n","    \n","    soft_votes = [1 if vote > THRESHOLD else 0 for vote in soft_votes]\n","\n","    return soft_votes"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ye3M3ZZM_B0L"},"source":["roc_auc = roc_auc_score(xzt_all_labels, soft_votes)\n","fpr, tpr, thresholds = metrics.roc_curve(yzt_all_labels, soft_votes)\n","print(\"FPR {} \\n TPR: {} \\n THRESHOLDS: {} \\n\".format(fpr, tpr, thresholds))\n","\n","soft_proba = [1 - x for x in soft_votes] \n","\n","skplt.metrics.plot_roc(yzt_all_labels,\n","                       np.column_stack([soft_proba, soft_votes]))\n","plt.savefig(\"./test.jpg\", dpi=600, bbox_inches = \"tight\")\n","\n","plt.show()\n","\n","skplt.metrics.plot_precision_recall(yzt_all_labels,\n","                                    np.column_stack([soft_proba, soft_votes]))\n","plt.savefig(\"./west.jpg\", dpi=600, bbox_inches = \"tight\")\n","\n","plt.show()\n","\n","skplt.metrics.plot_cumulative_gain(yzt_all_labels,\n","                                   np.column_stack([soft_proba, soft_votes]))\n","plt.savefig(\"./mest.jpg\", dpi=600, bbox_inches = \"tight\")\n","\n","skplt.metrics.plot_lift_curve(yzt_all_labels,\n","                              np.column_stack([soft_proba, soft_votes]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqH96VVR_rBj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606237214109,"user_tz":-60,"elapsed":1995,"user":{"displayName":"Shruti Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjlnsO6ZJqh75mi4ALesQLq4jofkr4lg9wMx8kckzc=s64","userId":"05348310931573326252"}},"outputId":"af41cfdd-4c00-486e-9109-f09bc396f224"},"source":["results = []\n","\n","POINTS =  8550\n","\n","XYT = Path(\"/content/drive/My Drive/KM3Net Data/ensemble/xyt/\")\n","XZT = Path(\"/content/drive/My Drive/KM3Net Data/ensemble/xzt/\")\n","YZT = Path(\"/content/drive/My Drive/KM3Net Data/ensemble//yzt/\")\n","EVALUATE = Path(\"/content/drive/My Drive/KM3Net Data/ensemble/test/\")\n","\n","PATHS_DICT = {XYT: 'xyt',\n","              XZT: 'xzt',\n","              YZT: 'yzt'}\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","train_transforms = transforms.Compose([\n","                    PointSampler(POINTS),\n","                    Normalize(),\n","                    RandRotation_z(),\n","                    RandomNoise(),\n","                    ToTensor()])\n","\n","dummy_input = torch.randn(64, 3,1,dtype=torch.float).to(device)\n","starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n","# repetitions = 120\n","# total_time = 0\n","# timings=np.zeros((repetitions,1))\n","\n","# GPU-WARM-UP\n","for _ in range(10):\n","   _ = pointnet(dummy_input)\n","\n","for PATH in PATHS_DICT:\n","  starter.record()\n","\n","  file = PATHS_DICT[PATH] + \".pth\"\n","\n","  pointnet = PointNet()\n","  pointnet.eval()\n","  pointnet.load_state_dict(torch.load(PATH/file))\n","\n","  unseen_ds = UnseenPointCloudData(EVALUATE, transform=train_transforms)\n","  unseen_loader = DataLoader(dataset=unseen_ds)\n","  results.append(evaluate_unseen_data(unseen_loader))\n","\n","\n","ender.record()\n","torch.cuda.synchronize()\n","curr_time = starter.elapsed_time(ender) #<-- performance\n","        # timings[epoch] = curr_time #<-- performance\n","print(\"Results From 3 Models: \", results)\n","print('Train dataset size: ', len(unseen_ds))\n","print('Sample pointcloud shape: ', unseen_ds[0]['pointcloud'].size())\n","print(\"Hard Voting Results: \", hard_voting(results))\n","print(\"Soft Voting Results: \", soft_voting(results))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["PCD_PATH:  /content/drive/My Drive/KM3Net Data/ensemble/test/group_1063_mesh.off\n","Predicted Label:   0\n","------\n","PCD_PATH:  /content/drive/My Drive/KM3Net Data/ensemble/test/group_1063_mesh.off\n","Predicted Label:   0\n","------\n","PCD_PATH:  /content/drive/My Drive/KM3Net Data/ensemble/test/group_1063_mesh.off\n","Predicted Label:   0\n","------\n","Results From 3 Models:  [[0], [0], [0]]\n","Train dataset size:  1\n","PCD_PATH:  /content/drive/My Drive/KM3Net Data/ensemble/test/group_1063_mesh.off\n","Sample pointcloud shape:  torch.Size([8550, 3])\n","Hard Voting Results:  [0]\n","Soft Voting Results:  [0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B381BWFbKql5","executionInfo":{"status":"ok","timestamp":1606237224758,"user_tz":-60,"elapsed":835,"user":{"displayName":"Shruti Rao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjlnsO6ZJqh75mi4ALesQLq4jofkr4lg9wMx8kckzc=s64","userId":"05348310931573326252"}},"outputId":"92da2765-b93b-4240-e3c9-640561dbdd3f"},"source":["curr_time"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["370.8993225097656"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"_ypAS01yMvuN"},"source":[""],"execution_count":null,"outputs":[]}]}