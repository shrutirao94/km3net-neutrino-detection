{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requirement is that with just 3D meshes, time difference information is lost. We need to keep the time difference in the data as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# XYZ Points\n",
    "\n",
    "Here we want to try if pointnet can understand just `x, y, z` points. `time` is not part of this data. \n",
    "\n",
    "NOTE: Need to evenly sample points for each timeslice.\n",
    "\n",
    "Techniques:\n",
    "<uo>\n",
    "    <li> Change Class Weights in PyTorch to make it pay more attention to undersampled classes\n",
    "    <li> Upsample \n",
    "    <li> Downsample\n",
    "    <li> Metrics\n",
    "        <uo>\n",
    "            <li> Area under ROC curve\n",
    "        </uo>\n",
    "</uo>\n",
    "\n",
    "**Q:** How unevenly is the data imbalanced? Hits vs noise points rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.0:\n",
    "\n",
    "**Date:** 17-July-2020\n",
    "\n",
    "**Rationale:**\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "**Train Results:**\n",
    "\n",
    "**Test Results:**\n",
    "\n",
    "**Comments:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 3D Meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.0:\n",
    "\n",
    "**Date:** 09-Jul-2020\n",
    "\n",
    "**Parameters:**\n",
    "1024 points\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. logsoftmax\n",
    "\n",
    "**Train Results:**\n",
    "50 %, 40 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %\n",
    "\n",
    "**Test Results:**\n",
    "<img src=\"../assets/experiments/exp_1.0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Exp 2.0:\n",
    "\n",
    "**Date:** 10-Jul-2020\n",
    "\n",
    "**Parameters:**\n",
    "1024 points\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. **Changed: LogSigmoid** \n",
    "\n",
    "**Train Results:**\n",
    "50 %, 40 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 54 %, 50 %, 59 %\n",
    "\n",
    "**Test Results:**\n",
    " <img src=\"../assets/experiments/exp_2.0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exp 2.1:\n",
    "\n",
    "**Date:** 10-Jul-2020\n",
    "\n",
    "**Parameters:**\n",
    "1024 points\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. **Changed: Sigmoid** \n",
    "\n",
    "**Rationale**\n",
    "\n",
    "Does changing between log sigmoid vs sigmoid have any effect on results?\n",
    "It actually decreased training performance\n",
    "\n",
    "**Train Results:**\n",
    "50 %, 40 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 45 %, 45 %\n",
    "\n",
    "**Test Results:**\n",
    " <img src=\"../assets/experiments/exp_2.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Exp 3.0: \n",
    "**Date:** -Jul-2020\n",
    "\n",
    "**Results:**\n",
    "1024 Max points\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. **Changed:LossFunction - BinaryEntropyLoss**\n",
    "\n",
    "**Rationale**\n",
    "The loss function for predicting binary outcomes should be Binary Loss Entropy\n",
    "\n",
    "**Result**\n",
    "\n",
    "No real difference between negative log likelihood loss mathematically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exp 3.1:\n",
    "**Date:** -Jul-2020\n",
    "\n",
    "**Parameters:**\n",
    "1024 Max points\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. **Changed:LossFunction - CrossEntropyLoss**\n",
    "\n",
    "**Rationale**\n",
    "Binary Loss Entropy did not work. Tried Crossentropy (multiclass as binary problem)\n",
    "\n",
    "**Train Results:**\n",
    "50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 54 %, 54 %\n",
    "\n",
    "**Test Results:**\n",
    "<img src=\"../assets/experiments/exp_3.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 4.0:\n",
    "**Date:** 13-Jul-2020\n",
    "\n",
    "**Parameters: Evaluating a Larger Model**\n",
    "**Changed: Max points to 2048**\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "50 %, 40 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %, 50 %\n",
    "\n",
    "**Remarks**\n",
    "No real difference\n",
    "\n",
    "**Test Results:**\n",
    "<!-- <img src=\"../assets/experiments/\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Exp 5.0:\n",
    "**Date:** 13-Jul-2020\n",
    "\n",
    "**Parameters:**\n",
    "**Changed: Increased files to 200 per type**\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "50 %, 50 %, 50 %, 55 %, 43 %, 45 %, 53 %, 60 %, 50 %, 50 %, 47 %, 47 %, 50 %, 47 %, 46 %\n",
    "\n",
    "\n",
    "[Epoch: 1, Batch:   10 /   10], loss: 0.569\n",
    "\n",
    "[Epoch: 2, Batch:   10 /   10], loss: 0.243\n",
    "\n",
    "[Epoch: 3, Batch:   10 /   10], loss: 0.126\n",
    "\n",
    "[Epoch: 4, Batch:   10 /   10], loss: 0.074\n",
    "\n",
    "[Epoch: 5, Batch:   10 /   10], loss: 0.050\n",
    "\n",
    "[Epoch: 6, Batch:   10 /   10], loss: 0.038\n",
    "\n",
    "[Epoch: 7, Batch:   10 /   10], loss: 0.028\n",
    "\n",
    "[Epoch: 8, Batch:   10 /   10], loss: 0.022\n",
    "\n",
    "[Epoch: 9, Batch:   10 /   10], loss: 0.019\n",
    "\n",
    "[Epoch: 10, Batch:   10 /   10], loss: 0.016\n",
    "\n",
    "[Epoch: 11, Batch:   10 /   10], loss: 0.014\n",
    "\n",
    "[Epoch: 12, Batch:   10 /   10], loss: 0.013\n",
    "\n",
    "[Epoch: 13, Batch:   10 /   10], loss: 0.011\n",
    "\n",
    "[Epoch: 14, Batch:   10 /   10], loss: 0.010\n",
    "\n",
    "[Epoch: 15, Batch:   10 /   10], loss: 0.009\n",
    "\n",
    "\n",
    "**Remarks**\n",
    "Produced 60% validation scores. Loss decrease rate stabalises around 10-11 epochs\n",
    "\n",
    "**Test Results:**\n",
    "<img src=\"../assets/experiments/exp_5.0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exp 5.1:\n",
    "**Date:** 13-Jul-2020\n",
    "\n",
    "**Parameters:**\n",
    "200 Files/Class\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. **Changed: Sigmoid **\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "50 %, 50 %, 50 %, 55 %, 43 %, 45 %, 53 %, 60 %, 50 %, 50 %, 47 %, 47 %, 50 %, 47 %, 46 %\n",
    "\n",
    "\n",
    "**Rationale**\n",
    "Sigmoid produced a more precise confusion matrix despite lower scores\n",
    "\n",
    "\n",
    "**Remarks**\n",
    "Produced 60% validation scores. Loss decrease rate stabalises around 10-11 epochs\n",
    "\n",
    "**Test Results:**\n",
    "<img src=\"../assets/experiments/exp_5.0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4D Mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (XYT, XZT, YZT) + Ensemble\n",
    "\n",
    "Still to try:\n",
    "1. Oversample \n",
    "2. Undersample\n",
    "3. Larger Dataset\n",
    "4. Non Sampled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.0: \n",
    "**Date:** 05-August-2020\n",
    "\n",
    "**Condition:** 6550 points per timeslice were taken. Hits ordered first so\n",
    "that they would be selected first and the balance would be noise points\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "[Epoch: 14, Batch:   10 /   10], loss: 0.006\n",
    "Valid accuracy: 97 %\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       mixed       1.00      0.93      0.96        40\n",
    "       noise       0.93      1.00      0.96        40\n",
    "\n",
    "    accuracy                           0.96        80\n",
    "    macro avg       0.97      0.96     0.96        80\n",
    "    weighted avg    0.97      0.96     0.96        80\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_1.0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.1: \n",
    "**Date:** 05-August-2020\n",
    "\n",
    "**Condition**\n",
    "\n",
    "Test data must not be 6550 points (Previously, train data )\n",
    "\n",
    "1. Split to train/test\n",
    "2. Train is resampled down to 6550 pints only\n",
    "3. Test is left untouched\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised, 6550 points\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "[Epoch: 14, Batch:   10 /   10], loss: 0.009\n",
    "Valid accuracy: 50 %\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "Classification report for Pointnet:\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       mixed       0.29      0.10      0.15        40\n",
    "       noise       0.45      0.75      0.57        40\n",
    "\n",
    "    accuracy                           0.42        80\n",
    "       macro avg       0.37      0.42      0.36        80\n",
    "    weighted avg       0.37      0.42      0.36        80\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_1.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.2: \n",
    "**Date:** 08-August-2020\n",
    "\n",
    "**Condition**\n",
    "6550 train, all test\n",
    "\n",
    "\n",
    "1. Split to train/test\n",
    "2. Train is resampled down to 6550 pints only\n",
    "3. Test is left untouched\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised, 1024 points \n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "[Epoch: 10, Batch:   10 /   10], loss: 0.010\n",
    "Valid accuracy: 61 %\n",
    "\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "\n",
    "Classification report for Pointnet:\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       mixed       0.60      0.23      0.33        40\n",
    "       noise       0.52      0.85      0.65        40\n",
    "\n",
    "    accuracy                           0.54        80\n",
    "   macro avg       0.56      0.54      0.49        80\n",
    "weighted avg       0.56      0.54      0.49        80\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_1.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.3: \n",
    "**Date:** 08-August-2020\n",
    "\n",
    "**Condition**\n",
    "6550 train, all test\n",
    "\n",
    "\n",
    "1. Split to train/test\n",
    "2. Train is resampled down to 6550 pints only\n",
    "3. Test is left untouched\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised, 1024 points \n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. **Sigmoid**\n",
    "5. **BCELoss**\n",
    "5. **30 epochs**\n",
    "\n",
    "**Train Results:**\n",
    "Valid accuracy: 55 %\n",
    "[Epoch: 23, Batch:   10 /   10], loss: 0.114\n",
    "\n",
    "Also, loss was fluctuating and never settled into minima\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "\n",
    "Classification report for Pointnet:\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       mixed       0.52      0.60      0.56        40\n",
    "       noise       0.53      0.45      0.49        40\n",
    "\n",
    "    accuracy                           0.53        80\n",
    "    macro avg       0.53      0.53     0.52        80\n",
    "    weighted avg    0.53      0.53     0.52        80\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_1.3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.4: \n",
    "**Date:** 08-August-2020\n",
    "\n",
    "**Condition**\n",
    "6550 train, all test\n",
    "\n",
    "\n",
    "1. Split to train/test\n",
    "2. Train is resampled down to 6550 pints only\n",
    "3. Test is left untouched\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised, 1024 points \n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. **BCEWithLogitsLoss**\n",
    "5. **60 epochs**\n",
    "\n",
    "**Train Results:**\n",
    "[Epoch: 12, Batch:   10 /   10], loss: 0.130\n",
    "Valid accuracy: 65 %\n",
    "\n",
    "Also, loss was fluctuating and never settled into minima\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "Classification report for Pointnet:\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       mixed       0.52      0.35      0.42        40\n",
    "       noise       0.51      0.68      0.58        40\n",
    "\n",
    "    accuracy                           0.51        80\n",
    "    macro avg       0.51      0.51     0.50        80\n",
    "    weighted avg    0.51      0.51     0.50        80\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_1.4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 1.5: \n",
    "**Date:** 08-August-2020\n",
    "\n",
    "**Condition**\n",
    "6550 train, all test\n",
    "\n",
    "\n",
    "1. Split to train/test\n",
    "2. Train is resampled down to 6550 pints only\n",
    "3. Test is left untouched\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised, 1024 points \n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. **Cross Entropy Loss (includes sigmoid)**\n",
    "5. **80 epochs**\n",
    "\n",
    "**Train Results:**\n",
    "[Epoch: 59, Batch:   10 /   10], loss: 0.708\n",
    "Valid accuracy: 65 %\n",
    "\n",
    "Also, loss was fluctuating and never settled into minima (0.710-0.687)\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "Classification report for Pointnet:\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "        mixed       0.80      0.40      0.53        40\n",
    "        noise       0.60      0.90      0.72        40\n",
    "\n",
    "     accuracy                           0.65        80\n",
    "    macro avg       0.70      0.65      0.63        80\n",
    "    weighted avg    0.70      0.65      0.63        80\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_1.5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 2.0: \n",
    "**Date:** 05-August-2020\n",
    "\n",
    "**Condition:** No points sampled\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "[Epoch: 14, Batch:   10 /   10], loss: 0.009\n",
    "Valid accuracy: 57 %\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "               Classification report for Pointnet:\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       mixed       0.38      0.15      0.21        40\n",
    "       noise       0.47      0.75      0.58        40\n",
    "\n",
    "    accuracy                           0.45        80\n",
    "    macro avg       0.42      0.45     0.40        80\n",
    "    weighted avg    0.42      0.45     0.40        80\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_2.0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 2.1: \n",
    "**Date:** 08-August-2020\n",
    "\n",
    "**Condition:** No points sampled\n",
    "    \n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised, 1024 points (instead of 6550)\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. LogSigmoid\n",
    "5. NNLoss\n",
    "\n",
    "**Train Results:**\n",
    "\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_2.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 3.0: \n",
    "**Date:** 08-August-2020\n",
    "\n",
    "**Condition:** Classes set to **k = 1** (instead of k = 2)\n",
    "\n",
    "**Parameters:**\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "4. Sigmoid\n",
    "5. BCE\n",
    "6. 80 epochs\n",
    "\n",
    "**Train Results:**\n",
    "\n",
    "\n",
    "**Classification report**\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../assets/experiments/ensemble/exp_3.0.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 4.0: Ensemble Best Loss Functiom\n",
    "\n",
    "Choosing the best loss function: BCEWith Logits, NLLLoss, CrossEntropyLoss\n",
    "\n",
    "**Date:** 15-August-2020\n",
    "\n",
    "No 6550 points, full data\n",
    "\n",
    "**Condition:** \n",
    "Batch:[32, 64]\n",
    "Epoch: 250    \n",
    "    \n",
    "**Parameters:**\n",
    "1. Sampled, normalised,\n",
    "2. Rotated\n",
    "3. Added Noise\n",
    "\n",
    "\n",
    "                   BCEWLogitsLoss     NLLoss      CELoss\n",
    "       Recall\n",
    "       \n",
    "       mixed           0.62             0.53       0.35  \n",
    "       noise           0.40             0.55       0.55\n",
    "\n",
    "\n",
    "       FPR             0.65             0.475       0.60\n",
    "       \n",
    "   \n",
    "BCEWithLogitsLoss gives highest acccuraccy but NLLoss gives lowest FPR overall.\n",
    "\n",
    "**Result: Proceed with NLLoss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output neuron looked something like this: [32, 2] matrix indicating that one neuron was assigned for. each class (k = 2). This makes it NOT a binary classification problem but a **Predicting a single label from multiple classes** problem.\n",
    "\n",
    "## Predicting a single label from multiple classes ##\n",
    "The final layer of the neural network will have one neuron for each of the classes and they will return a value between 0 and 1, which can be inferred as a probably. The output then results in a probability distribution as it sums to 1.\n",
    "To understand the accuracy of the prediction, each output is compared with its corresponding true value. True values have been one-hot-encoded meaning a 1 appears in the column corresponding to the correct category, else a 0 appears\n",
    "\n",
    "\n",
    "Softmax with cross entropy should be tried\n",
    "\n",
    "\n",
    "## Binary Classification Loss Functions [UPDATE: INVALID]\n",
    "\n",
    "[o] ***Binary Cross-Entropy:***\n",
    "Cross-entropy is the default loss function to use for binary classification problems. \n",
    "It is intended for use with binary classification where the target values are in the set {0, 1}. Mathematically, it is the preferred loss function under the inference framework of maximum \n",
    "likelihood. \n",
    "It is the loss function to be evaluated first and only changed if you have a good reason.\n",
    "Cross-entropy will calculate a score that summarizes the average difference between the actual and predicted probability distributions for predicting class 1. \n",
    "The score is minimized and a perfect cross-entropy value is 0.\n",
    "\n",
    "\n",
    "[x] ***Hinge Loss:*** \n",
    "An alternative to cross-entropy for binary classification problems is the hinge loss function, primarily developed for use with Support Vector Machine (SVM) models.It is intended for use with binary classification where the target values are in the set {-1, 1}.\n",
    "\n",
    "[x] ***Squared Hinge Loss:*** \n",
    "Calculates the square of the score hinge loss. It has the effect of smoothing the surface of the error function and making it numerically easier to work with. If using a hinge loss does result in better performance on a given binary classification problem, is likely that a squared hinge loss may be appropriate. As with using the hinge loss function, the target variable must be modified to have values in the set {-1, 1}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Test Available GPU on Colab\n",
    "<a id='gpu-test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm() ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:\n",
    "                print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' % \n",
    "                      (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noted that the read method converts to floats that looses several points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a 4th dimension: https://github.com/charlesq34/pointnet/issues/213\n",
    "https://github.com/charlesq34/pointnet/issues/12\n",
    "https://github.com/fxia22/pointnet.pytorch/issues/69\n",
    "\n",
    "\n",
    "Helpful visualisations: [https://github.com/Wind-Wing/pointnet-visualization/blob/master/visualization_report.pdf]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
