{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xyt Train & Test Data Preparation\n",
    "\n",
    "Here the data is prepared such that 6550 points, ordered and hits first can be taken for train and random points can be taken for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_stats(df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    General Stats on mixed and noise groups\n",
    "    \"\"\"\n",
    "    noise_stats = df_noise.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    mixed_stats = df_mixed.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    \n",
    "    neg, pos = np.bincount(df_mixed['label'])\n",
    "    total = neg + pos\n",
    "    \n",
    "    hits = df_mixed[df_mixed.label == 1].groupby(['group', 'label'])['label']\n",
    "    noise = df_mixed[df_mixed.label == 0].groupby(['group', 'label'])['label']\n",
    "    \n",
    "    hits_count = hits.count().sort_values(ascending=False)[:SIZE]\n",
    "    noise_count = noise.count().sort_values(ascending=False)[:SIZE]\n",
    "    \n",
    "    hits_to_noise = hits_count.droplevel(level='label')/noise_count.droplevel(level='label')\n",
    "    \n",
    "    class_imbalance = df_mixed.groupby(['group', 'label'])['label'].count()[:20]\n",
    "    \n",
    "        \n",
    "    print(\"NOISE STATS: \\n{}\\n\".format(noise_stats))\n",
    "    print(\"MIXED STATS: \\n{}\\n\".format(mixed_stats))\n",
    "    \n",
    "    print(\"Mixed Groups: \\n\")\n",
    "    print(\"Examples:\\n Total: {}\\n Positive: {} ({:.2f}% of total)\\n\".format(total,\n",
    "                                                                             pos, 100 * pos / total))\n",
    "    \n",
    "    print(\"Example of class imbalance in mixed groups: \\n \".format(class_imbalance.head()))\n",
    "           \n",
    "    print(\"Hits Only (Within mixed groups):\\n\")\n",
    "    print(\"The largest hits for a group: {}\\n\".format(hits_count.max()))\n",
    "    print(\"The smallest hits for a group: {}\\n\".format(hits_count.min()))\n",
    "    print(\"The mean hits for a group: {}\\n\".format(hits_count.mean()))\n",
    "                                                                                                                                    \n",
    "    print(\"Noise Only (Within mixed groups):\\n\") \n",
    "    print(\"The largest noise for a group: {}\\n\".format(noise_count.max()))\n",
    "    print(\"The smallest noise for a group: {}\\n\".format(noise_count.min())) \n",
    "    print(\"The mean noise for a group: {}\\n\".format(noise_count.mean()))\n",
    "    print(\"Hits-Noise Ratio:\\n\") \n",
    "    print(\"The highest ratio: {:.2f}% ({})\\n\".format(hits_to_noise.max()*100,\n",
    "                                                    hits_to_noise.max()))\n",
    "    print(\"The smallest ratio: {:.2f}% ({}) \\n\".format(hits_to_noise.min()*100,\n",
    "                                                       hits_to_noise.min())) \n",
    "    print(\"The mean ratio: {:.2f}% ({})\\n\".format(hits_to_noise.mean()*100, \n",
    "                                                  hits_to_noise.mean()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot(df_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of full data in mixed groups\n",
    "    \"\"\"\n",
    "    pos_df = pd.DataFrame(df_mixed[df_mixed.label == 1], columns = df_mixed.columns)\n",
    "    neg_df = pd.DataFrame(df_mixed[df_mixed.label == 0], columns = df_mixed.columns)\n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"Positive distribution (Hits) for pos_z vs time\")\n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"Negative distribution (Noise) for pos_z vs time\")\n",
    "    \n",
    "    plt.savefig(\"../../assets/Distributon of points in Mixed Groups (posz-time)\")\n",
    "    \n",
    "\n",
    "def sampled_plot(sampled_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of equally sampled points in mixed groups\n",
    "    \"\"\"\n",
    "    list_mixed_groups = df_mixed.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    data_subset = sampled_mixed.loc[sampled_mixed['group'].isin(list_mixed_groups)]\n",
    "    pos_df = data_subset[data_subset.label == 1]\n",
    "    neg_df = data_subset[data_subset.label == 0]\n",
    "    \n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"EQUAL SAMPLING: Positive distribution (Hits) for pos_z vs time\")\n",
    "    \n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"EQUAL SAMPLING: Negative distribution (Noise) for pos_z vs time\")\n",
    "\n",
    "    plt.savefig(\"../../assets/Distributon of Equally Sampled points in Mixed Groups (posz-time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(READ_PATH):\n",
    "    \"\"\"\n",
    "    Read CSV at specified Path\n",
    "    \"\"\"\n",
    "    return pd.read_csv(READ_PATH)\n",
    "\n",
    "\n",
    "def identify_groups(df):\n",
    "    \"\"\"\n",
    "    1. Tag groups that have only noise [0]\n",
    "    2. Tag groups that have both noise and hits [0,1]\n",
    "    3. Separate noise groups and hits+noise groups\n",
    "    \"\"\"\n",
    "    # Label groups by noise and and hits\n",
    "    df_count_label_type = pd.DataFrame(df.groupby('group')['label'].unique()).reset_index()\n",
    "    \n",
    "    # Obtain groups with only hits\n",
    "    df_noise = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) == 1]\n",
    "    \n",
    "    # Obtain groups with noise && hits\n",
    "    df_mixed = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) > 1]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def generate_dfs(df, df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    Obtain full dataframe based on identified noise\n",
    "    only groups and mixed groups\n",
    "    \"\"\"\n",
    "    df_noise = df[df.group.isin(df_noise.group)]\n",
    "    df_mixed = df[df.group.isin(df_mixed.group)]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def identify_top_groups(df, SIZE):\n",
    "    \"\"\"\n",
    "    Obtain a list of the top groups to be selected as \n",
    "    per SIZE\n",
    "    \n",
    "    **Note: SIZE == 200**\n",
    "    \"\"\"\n",
    "    top_groups = df.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    top_groups = list(top_groups.index)\n",
    "    \n",
    "    return top_groups\n",
    "\n",
    "\n",
    "def randomize_files(files):\n",
    "    \"\"\"\n",
    "    Shuffles files in a random order\n",
    "    \"\"\"\n",
    "    return shuffle(files)\n",
    "\n",
    "\n",
    "def prepare_split(files):\n",
    "    \"\"\"\n",
    "    Identifies the ratios for files to be split into\n",
    "    \n",
    "    **Note**\n",
    "    Current setting is for 80-20\n",
    "    \"\"\"\n",
    "    eighty = int(0.8 * len(files))\n",
    "    twenty = int(len(files) - eighty)\n",
    "    files = np.array(files)\n",
    "    \n",
    "    return eighty, twenty, files\n",
    "\n",
    "\n",
    "def generate_ids(eighty, twenty):\n",
    "    \"\"\"\n",
    "    Assigns 1 to 80% of the files and 0 to 20% of the files\n",
    "    \"\"\"\n",
    "    idx = np.hstack((np.ones(eighty),\n",
    "                     np.zeros(twenty)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def train_test_split(files, idx):\n",
    "    \"\"\"\n",
    "    Files tagged as 1 are categorised as training files\n",
    "    Files tagged as 0 are categorised as test files\n",
    "    \"\"\"\n",
    "    train = files[idx == 1]\n",
    "    test = files[idx == 0]\n",
    "    print(\"TRAIN SET: {0}\".format(train))\n",
    "    print(\"TEST SET: {0}\".format(test))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def generate_train_test(df):\n",
    "    top_groups = identify_top_groups(df, SIZE)\n",
    "    randomize_files(top_groups)\n",
    "    eighty, twenty, files = prepare_split(top_groups)\n",
    "    idx = generate_ids(eighty, twenty)\n",
    "    train, test = train_test_split(files, idx) \n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def sort_groups(df):\n",
    "    \"\"\"\n",
    "    Within each mixed groups (hits + noise), we need to sort\n",
    "    groups such that those with highest hits are selected first\n",
    "    \n",
    "    DataFrame --> List(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # group by groups and labels and associated counts for each label\n",
    "    grouped_df = pd.DataFrame(df.groupby(['group', 'label'])['label'].count())\n",
    "    grouped_df = grouped_df.rename(columns={'label':'count'})\n",
    "    \n",
    "    # sort groups based on highest occurance of hits\n",
    "    grouped_sorted_df = grouped_df.sort_values(grouped_df.columns.tolist())\\\n",
    "                            .sort_index(level=1, ascending=False, sort_remaining=False)\\\n",
    "                            .reset_index()\n",
    "    \n",
    "    # Obtain list of groups with highest hits based on sorted order\n",
    "    sorted_groups_list = pd.DataFrame(grouped_sorted_df.group)\n",
    "\n",
    "    # Drop duplicate groups\n",
    "    sorted_groups_list = sorted_groups_list.drop_duplicates()\n",
    "\n",
    "    # Count the occurances of groups (should only occur once)\n",
    "    sorted_groups_list['g'] = sorted_groups_list.groupby('group').cumcount()\n",
    "\n",
    "    # Make copy of dataframe\n",
    "    copy_df = df\n",
    "    \n",
    "    # Save original index positions as a column\n",
    "    copy_df_indices = copy_df.reset_index()\n",
    "    \n",
    "    # Make a count of occurances for each group\n",
    "    copy_df_indices['group_count'] = copy_df_indices.groupby('group').cumcount() \n",
    "    \n",
    "    # Merge the list of groups with the partial df to obtain corresponding full dataframe\n",
    "    copy_df = sorted_groups_list.merge(copy_df_indices)\\\n",
    "                                .set_index('index')\\\n",
    "                                .rename_axis(None)\\\n",
    "                                .drop(['group_count', 'g'], axis=1)\n",
    "    \n",
    "    # For each group, sort by labels within each group starting from 1 till 0\n",
    "    df = copy_df.groupby(['group'], sort=False)\\\n",
    "                 .apply(lambda x: x.sort_values(['label'], ascending=False))\\\n",
    "                 .reset_index(drop=True)\n",
    "    \n",
    "    return df    \n",
    "\n",
    "\n",
    "def equal_sampling(df):\n",
    "    \"\"\"\n",
    "    Equally sample points from each timeslice group.\n",
    "    Use 6550 - min number of points in hits group\n",
    "    \n",
    "    **Note** \n",
    "    Sorting values on label ensures that max number of\n",
    "    hits per group is taken. \n",
    "    \n",
    "    **For example**\n",
    "    Group 1 has 6549 noise and 600 hits. Sorting first on hits will allow\n",
    "    sample to have 600 hits and 5950 noise. \n",
    "    Without any sorting, sample would have had 6549 noise and 1 hit\n",
    "    \"\"\"    \n",
    "    POINTS = 6550\n",
    "    return df.groupby('group', sort=False)\\\n",
    "             .head(POINTS)\\\n",
    "             .reset_index(drop=True)\n",
    "\n",
    "\n",
    "def remove_groups(df):\n",
    "    \"\"\"\n",
    "    Remove groups that have less than 6550 members per timeslice\n",
    "    group\n",
    "    \"\"\"\n",
    "    POINTS = 6550\n",
    "    g = df.groupby('group')\n",
    "    \n",
    "    return g.filter(lambda x: len(x) >= POINTS)\n",
    "\n",
    "\n",
    "def sample_noise_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample noise based on specified tag\n",
    "    \"\"\"\n",
    "    if tag == \"equal\":\n",
    "        sampled_noise = equal_sampling(df)\n",
    "        equal_sampled_noise = remove_groups(sampled_noise)\n",
    "\n",
    "        return equal_sampled_noise\n",
    "    \n",
    "    \n",
    "def sample_mixed_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample mixed data based on specified tag\n",
    "    \"\"\"\n",
    "    df = sort_groups(df)\n",
    "    \n",
    "    if tag == \"equal\":\n",
    "        return equal_sampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_noise_test(df_noise, test, WRITE_NOISE_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled noise test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TEST + file_name,\n",
    "                   df_noise[df_noise.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_NOISE_TEST))\n",
    "    \n",
    "def save_mixed_test(df_mixed, test, WRITE_MIXED_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled mixed test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TEST + file_name,\n",
    "                   df_mixed[df_mixed.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_MIXED_TEST))\n",
    "    \n",
    "    \n",
    "def save_noise_train(sampled_df, train, WRITE_NOISE_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled noise train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_NOISE_TRAIN))\n",
    "    \n",
    "    \n",
    "def save_mixed_train(sampled_df, train, WRITE_MIXED_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled mixed train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_MIXED_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_PATH = \"../../data/simplified_data.csv\"\n",
    "WRITE_NOISE_TRAIN = \"../../data/ensemble/xyt/points/noise/train/\"\n",
    "WRITE_NOISE_TEST = \"../../data/ensemble/xyt/points/noise/test/\"\n",
    "\n",
    "WRITE_MIXED_TRAIN =  \"../../data/ensemble/xyt/points/mixed/train/\"\n",
    "WRITE_MIXED_TEST = \"../../data/ensemble/xyt/points/mixed/test/\"\n",
    "\n",
    "SIZE = 200\n",
    "\n",
    "df = read_csv(READ_PATH)\n",
    "df_noise, df_mixed = identify_groups(df)\n",
    "df_noise, df_mixed = generate_dfs(df, df_noise, df_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: [2957  374 3925 3152 1101 4799 3985  788 1189 2719 4591 5511  669 5006\n",
      " 5922 6436 6139 2875  210  474 5337 4328 1325 5067 3974 4796 5648 5149\n",
      "  601 4274 1204 6132 3941  909 4477 1016 5905 5840 4081 4870  583 4060\n",
      " 2272  648 3340 4848 4615 6241 1846 1567 3704 4032 5190 5434 1202 2621\n",
      " 1391 5701 3758 6177 5718 6630 2934 1129 2557 1955 6181 4391 2956 1681\n",
      " 1531 5991 1304 5103 4989 4199 2527    0  301 3352 2834 5510 4969  437\n",
      " 6560 3943 1639 1346 1108 2093  576 5038 1405 3960 4483 6432 4019 5941\n",
      "  449  208  758 3815 6333 3215 5977 5982 5605  630 3180 4640 6048  903\n",
      " 1481 5009 4426 3219 3189 3763  914 2197 4897 2751 2872  686 4444 3123\n",
      " 4571 3060 2533 3507 6427 3355 5182  416 2587 2128 3594 4695 3492 4671\n",
      " 6433 5222 2869 5578 3440  999  532 4590 4874 2658 1374  432 2932 5308\n",
      " 5412  990 1246 1583 6117 2414]\n",
      "TEST SET: [3168 3968 3403  347 1729 5491 1586 4647 5097 3042 6589 3416 3253  762\n",
      " 4775 4267 3487 4430  190 3222 3792 3799  134 3569 1333 2385 6396 5678\n",
      " 6555 1620 1151 4463 1055 3609 4179 1667 1413 5550 4900 6540]\n",
      "All 40 files saved successfully in ../../data/ensemble/xyt/points/noise/test/!\n",
      "All 160 files saved successfully in ../../data/ensemble/xyt/points/noise/train/!\n"
     ]
    }
   ],
   "source": [
    "####NOISE####\n",
    "train, test = generate_train_test(df_noise)\n",
    "df_train_noise = df_noise[df_noise.group.isin(train)]\n",
    "df_train_noise = sample_noise_data(\"equal\", df_train_noise)\n",
    "\n",
    "save_noise_test(df_noise, test, WRITE_NOISE_TEST)\n",
    "save_noise_train(df_train_noise, train, WRITE_NOISE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: [  50  103 3845  166 6038 1275 4227 1599 2367 2517 5857 4282 1038 2098\n",
      "  530  831 5010  979 2795 6084 1973 5032 3727 1893 4791 4515 5847 4428\n",
      " 2890 5799 3628 5659 3923 3967 1194 2374 2211  554 5422 1516 5272 1836\n",
      " 1172 2567 4080 1163 4679 4132 4943 3483 2323  281 4717  857 4301 4327\n",
      " 4075 6534 1650  716  491   32 5795 5211  845  809 3490 5747  231  997\n",
      " 5295 6378 1209 2024 3001   55 1488  249 6134 6109 1918 6493 5219 3063\n",
      " 1584 2021 5270  615 6553 6314  411 6495 2711 2389 2642 3611 1232 1671\n",
      " 4532 3924 2231 6203 6426 4417 1344 4215 4243 2404 1869 6530 1484 1820\n",
      " 4562 1937 2185 3398  355 2099 3700 4569 1273 1637 4735 3514 5280 2338\n",
      " 1496  375  797  941 4926 1813 2821 5133 4347 6590 3315 2654 5116 5866\n",
      " 4646 1357 5281  394  102 3287 5234 4565 6337 5215 5883 6006 5725 3953\n",
      " 2759 3094 2362 4653  584 1926]\n",
      "TEST SET: [4793 6567 4854 1276 1446 4034 2330 1154 1454 3025 6542 3310 1184 6588\n",
      " 1653 2774 4740 5812  810 3670 3252 5312 1732 1214  988 5823 1658 2161\n",
      " 1825 5886 6221 3170 1657  477   36 5621 4460 3072 4958 5114]\n",
      "All 40 files saved successfully in ../../data/ensemble/xyt/points/mixed/test/!\n",
      "All 160 files saved successfully in ../../data/ensemble/xyt/points/mixed/train/!\n"
     ]
    }
   ],
   "source": [
    "####MIXED####\n",
    "train, test = generate_train_test(df_mixed)\n",
    "df_train_mixed = df_mixed[df_mixed.group.isin(train)]\n",
    "df_train_mixed = sample_mixed_data(\"equal\", df_train_mixed)\n",
    "\n",
    "save_mixed_test(df_mixed, test, WRITE_MIXED_TEST)\n",
    "save_mixed_train(df_train_mixed, train, WRITE_MIXED_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pos_z</th>\n",
       "      <th>time</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pos_x     pos_y     pos_z      time     group\n",
       "label                                                  \n",
       "0      26996090  26996090  26996090  26996090  26996090\n",
       "1        489906    489906    489906    489906    489906"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixed.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pos_z</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>935417</td>\n",
       "      <td>935417</td>\n",
       "      <td>935417</td>\n",
       "      <td>935417</td>\n",
       "      <td>935417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112583</td>\n",
       "      <td>112583</td>\n",
       "      <td>112583</td>\n",
       "      <td>112583</td>\n",
       "      <td>112583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group   pos_x   pos_y   pos_z    time\n",
       "label                                        \n",
       "0      935417  935417  935417  935417  935417\n",
       "1      112583  112583  112583  112583  112583"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_mixed.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
