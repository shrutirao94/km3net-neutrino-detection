{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xyt Train & Test Data Preparation\n",
    "\n",
    "Here the data is prepared such that 6550 points, ordered and hits first can be taken for train and random points can be taken for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_stats(df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    General Stats on mixed and noise groups\n",
    "    \"\"\"\n",
    "    noise_stats = df_noise.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    mixed_stats = df_mixed.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    \n",
    "    neg, pos = np.bincount(df_mixed['label'])\n",
    "    total = neg + pos\n",
    "    \n",
    "    hits = df_mixed[df_mixed.label == 1].groupby(['group', 'label'])['label']\n",
    "    noise = df_mixed[df_mixed.label == 0].groupby(['group', 'label'])['label']\n",
    "    \n",
    "    hits_count = hits.count().sort_values(ascending=False)[:SIZE]\n",
    "    noise_count = noise.count().sort_values(ascending=False)[:SIZE]\n",
    "    \n",
    "    hits_to_noise = hits_count.droplevel(level='label')/noise_count.droplevel(level='label')\n",
    "    \n",
    "    class_imbalance = df_mixed.groupby(['group', 'label'])['label'].count()[:20]\n",
    "    \n",
    "        \n",
    "    print(\"NOISE STATS: \\n{}\\n\".format(noise_stats))\n",
    "    print(\"MIXED STATS: \\n{}\\n\".format(mixed_stats))\n",
    "    \n",
    "    print(\"Mixed Groups: \\n\")\n",
    "    print(\"Examples:\\n Total: {}\\n Positive: {} ({:.2f}% of total)\\n\".format(total,\n",
    "                                                                             pos, 100 * pos / total))\n",
    "    \n",
    "    print(\"Example of class imbalance in mixed groups: \\n \".format(class_imbalance.head()))\n",
    "           \n",
    "    print(\"Hits Only (Within mixed groups):\\n\")\n",
    "    print(\"The largest hits for a group: {}\\n\".format(hits_count.max()))\n",
    "    print(\"The smallest hits for a group: {}\\n\".format(hits_count.min()))\n",
    "    print(\"The mean hits for a group: {}\\n\".format(hits_count.mean()))\n",
    "                                                                                                                                    \n",
    "    print(\"Noise Only (Within mixed groups):\\n\") \n",
    "    print(\"The largest noise for a group: {}\\n\".format(noise_count.max()))\n",
    "    print(\"The smallest noise for a group: {}\\n\".format(noise_count.min())) \n",
    "    print(\"The mean noise for a group: {}\\n\".format(noise_count.mean()))\n",
    "    print(\"Hits-Noise Ratio:\\n\") \n",
    "    print(\"The highest ratio: {:.2f}% ({})\\n\".format(hits_to_noise.max()*100,\n",
    "                                                    hits_to_noise.max()))\n",
    "    print(\"The smallest ratio: {:.2f}% ({}) \\n\".format(hits_to_noise.min()*100,\n",
    "                                                       hits_to_noise.min())) \n",
    "    print(\"The mean ratio: {:.2f}% ({})\\n\".format(hits_to_noise.mean()*100, \n",
    "                                                  hits_to_noise.mean()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot(df_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of full data in mixed groups\n",
    "    \"\"\"\n",
    "    pos_df = pd.DataFrame(df_mixed[df_mixed.label == 1], columns = df_mixed.columns)\n",
    "    neg_df = pd.DataFrame(df_mixed[df_mixed.label == 0], columns = df_mixed.columns)\n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"Positive distribution (Hits) for pos_z vs time\")\n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"Negative distribution (Noise) for pos_z vs time\")\n",
    "    \n",
    "    plt.savefig(\"../../assets/Distributon of points in Mixed Groups (posz-time)\")\n",
    "    \n",
    "\n",
    "def sampled_plot(sampled_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of equally sampled points in mixed groups\n",
    "    \"\"\"\n",
    "    list_mixed_groups = df_mixed.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    data_subset = sampled_mixed.loc[sampled_mixed['group'].isin(list_mixed_groups)]\n",
    "    pos_df = data_subset[data_subset.label == 1]\n",
    "    neg_df = data_subset[data_subset.label == 0]\n",
    "    \n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"EQUAL SAMPLING: Positive distribution (Hits) for pos_z vs time\")\n",
    "    \n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"EQUAL SAMPLING: Negative distribution (Noise) for pos_z vs time\")\n",
    "\n",
    "    plt.savefig(\"../../assets/Distributon of Equally Sampled points in Mixed Groups (posz-time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(READ_PATH):\n",
    "    \"\"\"\n",
    "    Read CSV at specified Path\n",
    "    \"\"\"\n",
    "    return pd.read_csv(READ_PATH)\n",
    "\n",
    "\n",
    "def identify_groups(df):\n",
    "    \"\"\"\n",
    "    1. Tag groups that have only noise [0]\n",
    "    2. Tag groups that have both noise and hits [0,1]\n",
    "    3. Separate noise groups and hits+noise groups\n",
    "    \"\"\"\n",
    "    # Label groups by noise and and hits\n",
    "    df_count_label_type = pd.DataFrame(df.groupby('group')['label'].unique()).reset_index()\n",
    "    \n",
    "    # Obtain groups with only hits\n",
    "    df_noise = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) == 1]\n",
    "    \n",
    "    # Obtain groups with noise && hits\n",
    "    df_mixed = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) > 1]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def generate_dfs(df, df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    Obtain full dataframe based on identified noise\n",
    "    only groups and mixed groups\n",
    "    \"\"\"\n",
    "    df_noise = df[df.group.isin(df_noise.group)]\n",
    "    df_mixed = df[df.group.isin(df_mixed.group)]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def identify_top_groups(df, SIZE):\n",
    "    \"\"\"\n",
    "    Obtain a list of the top groups to be selected as \n",
    "    per SIZE\n",
    "    \n",
    "    **Note: SIZE == 200**\n",
    "    \"\"\"\n",
    "    top_groups = df.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    top_groups = list(top_groups.index)\n",
    "    \n",
    "    return top_groups\n",
    "\n",
    "\n",
    "def randomize_files(files):\n",
    "    \"\"\"\n",
    "    Shuffles files in a random order\n",
    "    \"\"\"\n",
    "    return shuffle(files)\n",
    "\n",
    "\n",
    "def prepare_split(files):\n",
    "    \"\"\"\n",
    "    Identifies the ratios for files to be split into\n",
    "    \n",
    "    **Note**\n",
    "    Current setting is for 80-20\n",
    "    \"\"\"\n",
    "    eighty = int(0.8 * len(files))\n",
    "    twenty = int(len(files) - eighty)\n",
    "    files = np.array(files)\n",
    "    \n",
    "    return eighty, twenty, files\n",
    "\n",
    "\n",
    "def generate_ids(eighty, twenty):\n",
    "    \"\"\"\n",
    "    Assigns 1 to 80% of the files and 0 to 20% of the files\n",
    "    \"\"\"\n",
    "    idx = np.hstack((np.ones(eighty),\n",
    "                     np.zeros(twenty)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def train_test_split(files, idx):\n",
    "    \"\"\"\n",
    "    Files tagged as 1 are categorised as training files\n",
    "    Files tagged as 0 are categorised as test files\n",
    "    \"\"\"\n",
    "    train = files[idx == 1]\n",
    "    test = files[idx == 0]\n",
    "    print(\"TRAIN SET: {0}\".format(train))\n",
    "    print(\"TEST SET: {0}\".format(test))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def generate_train_test(df, tag):\n",
    "    if tag == \"noise\":\n",
    "        top_groups = identify_top_groups(df, SIZE)\n",
    "    else:\n",
    "        top_groups = list(sort_groups(df).group.unique()[:SIZE])\n",
    "    \n",
    "    randomize_files(top_groups)\n",
    "    eighty, twenty, files = prepare_split(top_groups)\n",
    "    idx = generate_ids(eighty, twenty)\n",
    "    train, test = train_test_split(files, idx) \n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def sort_groups(df):\n",
    "    \"\"\"\n",
    "    Within each mixed groups (hits + noise), we need to sort\n",
    "    groups such that those with highest hits are selected first\n",
    "    \n",
    "    DataFrame --> List(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # group by groups and labels and associated counts for each label\n",
    "    grouped_df = pd.DataFrame(df.groupby(['group', 'label'])['label'].count())\n",
    "    grouped_df = grouped_df.rename(columns={'label':'count'})\n",
    "    \n",
    "    # sort groups based on highest occurance of hits\n",
    "    grouped_sorted_df = grouped_df.sort_values(grouped_df.columns.tolist())\\\n",
    "                            .sort_index(level=1, ascending=False, sort_remaining=False)\\\n",
    "                            .reset_index()\n",
    "    \n",
    "    # Obtain list of groups with highest hits based on sorted order\n",
    "    sorted_groups_list = pd.DataFrame(grouped_sorted_df.group)\n",
    "\n",
    "    # Drop duplicate groups\n",
    "    sorted_groups_list = sorted_groups_list.drop_duplicates()\n",
    "\n",
    "    # Count the occurances of groups (should only occur once)\n",
    "    sorted_groups_list['g'] = sorted_groups_list.groupby('group').cumcount()\n",
    "\n",
    "    # Make copy of dataframe\n",
    "    copy_df = df\n",
    "    \n",
    "    # Save original index positions as a column\n",
    "    copy_df_indices = copy_df.reset_index()\n",
    "    \n",
    "    # Make a count of occurances for each group\n",
    "    copy_df_indices['group_count'] = copy_df_indices.groupby('group').cumcount() \n",
    "    \n",
    "    # Merge the list of groups with the partial df to obtain corresponding full dataframe\n",
    "    copy_df = sorted_groups_list.merge(copy_df_indices)\\\n",
    "                                .set_index('index')\\\n",
    "                                .rename_axis(None)\\\n",
    "                                .drop(['group_count', 'g'], axis=1)\n",
    "    \n",
    "    # For each group, sort by labels within each group starting from 1 till 0\n",
    "    df = copy_df.groupby(['group'], sort=False)\\\n",
    "                 .apply(lambda x: x.sort_values(['label'], ascending=False))\\\n",
    "                 .reset_index(drop=True)\n",
    "    \n",
    "    return df    \n",
    "\n",
    "\n",
    "def equal_sampling(df):\n",
    "    \"\"\"\n",
    "    Equally sample points from each timeslice group.\n",
    "    Use 6550 - min number of points in hits group\n",
    "    \n",
    "    **Note** \n",
    "    Sorting values on label ensures that max number of\n",
    "    hits per group is taken. \n",
    "    \n",
    "    **For example**\n",
    "    Group 1 has 6549 noise and 600 hits. Sorting first on hits will allow\n",
    "    sample to have 600 hits and 5950 noise. \n",
    "    Without any sorting, sample would have had 6549 noise and 1 hit\n",
    "    \"\"\"    \n",
    "    POINTS = 6550\n",
    "    return df.groupby('group', sort=False)\\\n",
    "             .head(POINTS)\\\n",
    "             .reset_index(drop=True)\n",
    "\n",
    "\n",
    "def remove_groups(df):\n",
    "    \"\"\"\n",
    "    Remove groups that have less than 6550 members per timeslice\n",
    "    group\n",
    "    \"\"\"\n",
    "    POINTS = 6550\n",
    "    g = df.groupby('group')\n",
    "    \n",
    "    return g.filter(lambda x: len(x) >= POINTS)\n",
    "\n",
    "\n",
    "def sample_noise_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample noise based on specified tag\n",
    "    \"\"\"\n",
    "    if tag == \"equal\":\n",
    "        sampled_noise = equal_sampling(df)\n",
    "        equal_sampled_noise = remove_groups(sampled_noise)\n",
    "\n",
    "        return equal_sampled_noise\n",
    "    \n",
    "    \n",
    "def sample_mixed_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample mixed data based on specified tag\n",
    "    \"\"\"\n",
    "    df = sort_groups(df)\n",
    "    \n",
    "    if tag == \"equal\":\n",
    "        return equal_sampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_noise_test(df_noise, test, WRITE_NOISE_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled noise test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TEST + file_name,\n",
    "                   df_noise[df_noise.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_NOISE_TEST))\n",
    "    \n",
    "def save_mixed_test(df_mixed, test, WRITE_MIXED_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled mixed test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TEST + file_name,\n",
    "                   df_mixed[df_mixed.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_MIXED_TEST))\n",
    "    \n",
    "    \n",
    "def save_noise_train(sampled_df, train, WRITE_NOISE_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled noise train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_NOISE_TRAIN))\n",
    "    \n",
    "    \n",
    "def save_mixed_train(sampled_df, train, WRITE_MIXED_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled mixed train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_MIXED_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_PATH = \"../../../data/simplified_data.csv\"\n",
    "WRITE_NOISE_TRAIN = \"../../../data/sampled/xyt/points/noise/train/\"\n",
    "WRITE_NOISE_TEST = \"../../../data/sampled/xyt/points/noise/test/\"\n",
    "\n",
    "WRITE_MIXED_TRAIN =  \"../../../data/sampled/xyt/points/mixed/train/\"\n",
    "WRITE_MIXED_TEST = \"../../../data/sampled/xyt/points/mixed/test/\"\n",
    "\n",
    "SIZE = 200\n",
    "\n",
    "df = read_csv(READ_PATH)\n",
    "df_noise, df_mixed = identify_groups(df)\n",
    "df_noise, df_mixed = generate_dfs(df, df_noise, df_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAND:  None\n",
      "80/20: \n",
      "  [4590 5222 1325 5103 1481 5922  686 3974 6333 4571 3168 3985 2385 3253\n",
      " 3943 6436 3219 2751 3215  474 3968 4060  903 4799 1055  788 3569 3222\n",
      " 4870 3594 1639 5337 1667 6589 1405 6560 2869 6181 1955 4426 3355 3440\n",
      " 5941  190 3487 5067 1346  762  648 3340 4274  347 4444  416 1204  758\n",
      " 2621 4848 3925 2128 5511 3815 2956  301  601  576 5905  374 1202 4430\n",
      " 4267  449 5412 1681  999 5190 5605  990  630  134  669 5038 3492 1189\n",
      " 3792 4695 5648 3799 6630 5434 5009 4391 3507 3042  437 4796 6177 3960\n",
      " 4647 2093  583 3704  432 4615 4640 3416 6432  532  208 5510 6396 4477\n",
      " 2719 6132 1620 5578  909 2587 1246 4775 5678  210 5701 2658 6555 1586\n",
      " 5491 5097 4081 5182 5550 1129 1151 1374 2557 3189 1729 4199 6427 5840\n",
      " 3403 2533 1531 5308 6433 4900 3758 1846 4969 3123 6117 3763 1413 3060\n",
      " 4671 2934 4463 6241 4179 4989 2872 6139 5991 4032 1333 1101 5977  914\n",
      " 5149 5006 4328 3152 4483 3352 5718 4897 1016 2834 1583 4591 1391 1108\n",
      " 3941 2414 2932 4874 2957 3609 4019 5982 6048 3180 2272 2875 6540 2527\n",
      "    0 1304 2197 1567]\n",
      "TRAIN SET: [4590 5222 1325 5103 1481 5922  686 3974 6333 4571 3168 3985 2385 3253\n",
      " 3943 6436 3219 2751 3215  474 3968 4060  903 4799 1055  788 3569 3222\n",
      " 4870 3594 1639 5337 1667 6589 1405 6560 2869 6181 1955 4426 3355 3440\n",
      " 5941  190 3487 5067 1346  762  648 3340 4274  347 4444  416 1204  758\n",
      " 2621 4848 3925 2128 5511 3815 2956  301  601  576 5905  374 1202 4430\n",
      " 4267  449 5412 1681  999 5190 5605  990  630  134  669 5038 3492 1189\n",
      " 3792 4695 5648 3799 6630 5434 5009 4391 3507 3042  437 4796 6177 3960\n",
      " 4647 2093  583 3704  432 4615 4640 3416 6432  532  208 5510 6396 4477\n",
      " 2719 6132 1620 5578  909 2587 1246 4775 5678  210 5701 2658 6555 1586\n",
      " 5491 5097 4081 5182 5550 1129 1151 1374 2557 3189 1729 4199 6427 5840\n",
      " 3403 2533 1531 5308 6433 4900 3758 1846 4969 3123 6117 3763 1413 3060\n",
      " 4671 2934 4463 6241 4179 4989]\n",
      "TEST SET: [2872 6139 5991 4032 1333 1101 5977  914 5149 5006 4328 3152 4483 3352\n",
      " 5718 4897 1016 2834 1583 4591 1391 1108 3941 2414 2932 4874 2957 3609\n",
      " 4019 5982 6048 3180 2272 2875 6540 2527    0 1304 2197 1567]\n",
      "All 40 files saved successfully in ../../../data/sampled/xyt/points/noise/test/!\n",
      "All 160 files saved successfully in ../../../data/sampled/xyt/points/noise/train/!\n"
     ]
    }
   ],
   "source": [
    "####NOISE####\n",
    "train, test = generate_train_test(df_noise, \"noise\")\n",
    "df_train_noise = df_noise[df_noise.group.isin(train)]\n",
    "df_train_noise = sample_noise_data(\"equal\", df_train_noise)\n",
    "\n",
    "save_noise_test(df_noise, test, WRITE_NOISE_TEST)\n",
    "save_noise_train(df_train_noise, train, WRITE_NOISE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP GROUPS:  [615, 1637, 5866, 5857, 1232, 2021, 554, 4301, 1273, 6495, 3170, 6588, 4958, 3398, 5747, 2211, 4565, 1599, 716, 3483, 4515, 6109, 6530, 5010, 5886, 3727, 5823, 375, 2323, 4735, 477, 1209, 2338, 2759, 1732, 4347, 1276, 3490, 1869, 2330, 3025, 2231, 979, 6378, 6038, 1214, 5234, 5312, 6534, 1584, 4282, 1671, 1344, 5799, 797, 5215, 1275, 1488, 5295, 1658, 6221, 4080, 4327, 1653, 1973, 4717, 2711, 355, 2654, 4243, 3923, 3001, 5114, 4679, 5621, 1918, 6553, 6314, 6542, 4532, 5422, 1194, 1038, 1484, 3310, 2362, 1813, 4428, 5725, 5116, 1516, 4926, 2024, 4417, 6567, 1496, 6084, 1163, 281, 3953, 4227, 5281, 584, 3670, 2367, 5270, 530, 1650, 3845, 5883, 4943, 3700, 2098, 4793, 32, 1357, 4646, 3287, 5133, 857, 941, 809, 1446, 1454, 50, 4215, 6006, 1836, 5032, 4034, 787, 3611, 4562, 2821, 1184, 4023, 5151, 2731, 3252, 1141, 1887, 3063, 6470, 1825, 2795, 2185, 3924, 2374, 3094, 4783, 4620, 5211, 5931, 440, 55, 249, 2389, 2517, 6054, 5812, 5815, 2567, 4854, 6493, 103, 231, 810, 4336, 691, 3778, 3212, 5659, 3967, 3514, 607, 997, 5030, 3740, 5000, 491, 1764, 394, 6564, 5976, 3084, 469, 4460, 6337, 1618, 4104, 1441, 5795, 4741, 6134, 3570, 2293, 988, 639, 2447, 1172]\n",
      "RAND:  None\n",
      "80/20: \n",
      "  [3398 6553  554  997  281 2323  797 5312 1184 5281 2821 6109  941 5747\n",
      " 1446 2374 1163 4034  491 4301 2338 1887 1618 4227  607 2231 2098 4926\n",
      "  249  231   55   32 4080 2447 5032  440 5133 5812 5815  584 1038 5886\n",
      "  355 6495 5114 1671 1172 1599 1357 2293 6314 5215 1869 5857 5234 3170\n",
      " 6084 4717 4532 4565 2517 5116 5621 1275 5823 3084 1488  103 5795 3700\n",
      " 1441  477 6567 6470 4336 6534 5931 3923 6542 6493 1637 3483 1653 2759\n",
      " 1732 1484 3514 4215  979 4562 4417 3001 3490 4783 4741 1658 2024 4282\n",
      "  810 1836 4793 3287  469 2330 3967 6337  988 5151 3845 5295 3924 1516\n",
      " 5422 3570 3740 6378 4620 1650 4460   50 5000  615 1276 2211 3212 4104\n",
      " 2711 1141 1813 1454 4679 4327  809  639 5799 2795 6054 3094 1232  394\n",
      " 6530 6134 4347 3063 2654 3025 5211 3727 1584  716 3778 5883 1214  530\n",
      " 1273 4735 4023 2185 6038 2389 5010 2731 1209 1825 5725  375 3670 6588\n",
      " 2367 1496 2021 5030 3310  787 1194 3611 6006 1764  691 2567 4943 4428\n",
      " 4646 4515 4854 6221 5270 5976 4243 1918 5659 5866 1344 4958 3252 1973\n",
      " 3953 2362 6564  857]\n",
      "TRAIN SET: [3398 6553  554  997  281 2323  797 5312 1184 5281 2821 6109  941 5747\n",
      " 1446 2374 1163 4034  491 4301 2338 1887 1618 4227  607 2231 2098 4926\n",
      "  249  231   55   32 4080 2447 5032  440 5133 5812 5815  584 1038 5886\n",
      "  355 6495 5114 1671 1172 1599 1357 2293 6314 5215 1869 5857 5234 3170\n",
      " 6084 4717 4532 4565 2517 5116 5621 1275 5823 3084 1488  103 5795 3700\n",
      " 1441  477 6567 6470 4336 6534 5931 3923 6542 6493 1637 3483 1653 2759\n",
      " 1732 1484 3514 4215  979 4562 4417 3001 3490 4783 4741 1658 2024 4282\n",
      "  810 1836 4793 3287  469 2330 3967 6337  988 5151 3845 5295 3924 1516\n",
      " 5422 3570 3740 6378 4620 1650 4460   50 5000  615 1276 2211 3212 4104\n",
      " 2711 1141 1813 1454 4679 4327  809  639 5799 2795 6054 3094 1232  394\n",
      " 6530 6134 4347 3063 2654 3025 5211 3727 1584  716 3778 5883 1214  530\n",
      " 1273 4735 4023 2185 6038 2389]\n",
      "TEST SET: [5010 2731 1209 1825 5725  375 3670 6588 2367 1496 2021 5030 3310  787\n",
      " 1194 3611 6006 1764  691 2567 4943 4428 4646 4515 4854 6221 5270 5976\n",
      " 4243 1918 5659 5866 1344 4958 3252 1973 3953 2362 6564  857]\n",
      "All 40 files saved successfully in ../../../data/sampled/xyt/points/mixed/test/!\n",
      "All 160 files saved successfully in ../../../data/sampled/xyt/points/mixed/train/!\n"
     ]
    }
   ],
   "source": [
    "####MIXED####\n",
    "train, test = generate_train_test(df_mixed, \"mixed\")\n",
    "df_train_mixed = df_mixed[df_mixed.group.isin(train)]\n",
    "df_train_mixed = sample_mixed_data(\"equal\", df_train_mixed)\n",
    "\n",
    "save_mixed_test(df_mixed, test, WRITE_MIXED_TEST)\n",
    "save_mixed_train(df_train_mixed, train, WRITE_MIXED_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
