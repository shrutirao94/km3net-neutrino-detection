{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xzt Train & Test Data Preparation\n",
    "\n",
    "Here the data is prepared such that 6550 points, ordered and hits first can be taken for train and random points can be taken for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_stats(df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    General Stats on mixed and noise groups\n",
    "    \"\"\"\n",
    "    noise_stats = df_noise.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    mixed_stats = df_mixed.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    \n",
    "    neg, pos = np.bincount(df_mixed['label'])\n",
    "    total = neg + pos\n",
    "    \n",
    "    hits = df_mixed[df_mixed.label == 1].groupby(['group', 'label'])['label']\n",
    "    noise = df_mixed[df_mixed.label == 0].groupby(['group', 'label'])['label']\n",
    "    \n",
    "    hits_count = hits.count().sort_values(ascending=False)[:SIZE]\n",
    "    noise_count = noise.count().sort_values(ascending=False)[:SIZE]\n",
    "    \n",
    "    hits_to_noise = hits_count.droplevel(level='label')/noise_count.droplevel(level='label')\n",
    "    \n",
    "    class_imbalance = df_mixed.groupby(['group', 'label'])['label'].count()[:20]\n",
    "    \n",
    "        \n",
    "    print(\"NOISE STATS: \\n{}\\n\".format(noise_stats))\n",
    "    print(\"MIXED STATS: \\n{}\\n\".format(mixed_stats))\n",
    "    \n",
    "    print(\"Mixed Groups: \\n\")\n",
    "    print(\"Examples:\\n Total: {}\\n Positive: {} ({:.2f}% of total)\\n\".format(total,\n",
    "                                                                             pos, 100 * pos / total))\n",
    "    \n",
    "    print(\"Example of class imbalance in mixed groups: \\n \".format(class_imbalance.head()))\n",
    "           \n",
    "    print(\"Hits Only (Within mixed groups):\\n\")\n",
    "    print(\"The largest hits for a group: {}\\n\".format(hits_count.max()))\n",
    "    print(\"The smallest hits for a group: {}\\n\".format(hits_count.min()))\n",
    "    print(\"The mean hits for a group: {}\\n\".format(hits_count.mean()))\n",
    "                                                                                                                                    \n",
    "    print(\"Noise Only (Within mixed groups):\\n\") \n",
    "    print(\"The largest noise for a group: {}\\n\".format(noise_count.max()))\n",
    "    print(\"The smallest noise for a group: {}\\n\".format(noise_count.min())) \n",
    "    print(\"The mean noise for a group: {}\\n\".format(noise_count.mean()))\n",
    "    print(\"Hits-Noise Ratio:\\n\") \n",
    "    print(\"The highest ratio: {:.2f}% ({})\\n\".format(hits_to_noise.max()*100,\n",
    "                                                    hits_to_noise.max()))\n",
    "    print(\"The smallest ratio: {:.2f}% ({}) \\n\".format(hits_to_noise.min()*100,\n",
    "                                                       hits_to_noise.min())) \n",
    "    print(\"The mean ratio: {:.2f}% ({})\\n\".format(hits_to_noise.mean()*100, \n",
    "                                                  hits_to_noise.mean()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot(df_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of full data in mixed groups\n",
    "    \"\"\"\n",
    "    pos_df = pd.DataFrame(df_mixed[df_mixed.label == 1], columns = df_mixed.columns)\n",
    "    neg_df = pd.DataFrame(df_mixed[df_mixed.label == 0], columns = df_mixed.columns)\n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"Positive distribution (Hits) for pos_z vs time\")\n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"Negative distribution (Noise) for pos_z vs time\")\n",
    "    \n",
    "    plt.savefig(\"../../assets/Distributon of points in Mixed Groups (posz-time)\")\n",
    "    \n",
    "\n",
    "def sampled_plot(sampled_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of equally sampled points in mixed groups\n",
    "    \"\"\"\n",
    "    list_mixed_groups = df_mixed.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    data_subset = sampled_mixed.loc[sampled_mixed['group'].isin(list_mixed_groups)]\n",
    "    pos_df = data_subset[data_subset.label == 1]\n",
    "    neg_df = data_subset[data_subset.label == 0]\n",
    "    \n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"EQUAL SAMPLING: Positive distribution (Hits) for pos_z vs time\")\n",
    "    \n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"EQUAL SAMPLING: Negative distribution (Noise) for pos_z vs time\")\n",
    "\n",
    "    plt.savefig(\"../../assets/Distributon of Equally Sampled points in Mixed Groups (posz-time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(READ_PATH):\n",
    "    \"\"\"\n",
    "    Read CSV at specified Path\n",
    "    \"\"\"\n",
    "    return pd.read_csv(READ_PATH)\n",
    "\n",
    "\n",
    "def identify_groups(df):\n",
    "    \"\"\"\n",
    "    1. Tag groups that have only noise [0]\n",
    "    2. Tag groups that have both noise and hits [0,1]\n",
    "    3. Separate noise groups and hits+noise groups\n",
    "    \"\"\"\n",
    "    # Label groups by noise and and hits\n",
    "    df_count_label_type = pd.DataFrame(df.groupby('group')['label'].unique()).reset_index()\n",
    "    \n",
    "    # Obtain groups with only hits\n",
    "    df_noise = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) == 1]\n",
    "    \n",
    "    # Obtain groups with noise && hits\n",
    "    df_mixed = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) > 1]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def generate_dfs(df, df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    Obtain full dataframe based on identified noise\n",
    "    only groups and mixed groups\n",
    "    \"\"\"\n",
    "    df_noise = df[df.group.isin(df_noise.group)]\n",
    "    df_mixed = df[df.group.isin(df_mixed.group)]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def identify_top_groups(df, SIZE):\n",
    "    \"\"\"\n",
    "    Obtain a list of the top groups to be selected as \n",
    "    per SIZE\n",
    "    \n",
    "    **Note: SIZE == 200**\n",
    "    \"\"\"\n",
    "    top_groups = df.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    top_groups = list(top_groups.index)\n",
    "    \n",
    "    return top_groups\n",
    "\n",
    "\n",
    "def randomize_files(files):\n",
    "    \"\"\"\n",
    "    Shuffles files in a random order\n",
    "    \"\"\"\n",
    "    return shuffle(files)\n",
    "\n",
    "\n",
    "def prepare_split(files):\n",
    "    \"\"\"\n",
    "    Identifies the ratios for files to be split into\n",
    "    \n",
    "    **Note**\n",
    "    Current setting is for 80-20\n",
    "    \"\"\"\n",
    "    eighty = int(0.8 * len(files))\n",
    "    twenty = int(len(files) - eighty)\n",
    "    files = np.array(files)\n",
    "    \n",
    "    return eighty, twenty, files\n",
    "\n",
    "\n",
    "def generate_ids(eighty, twenty):\n",
    "    \"\"\"\n",
    "    Assigns 1 to 80% of the files and 0 to 20% of the files\n",
    "    \"\"\"\n",
    "    idx = np.hstack((np.ones(eighty),\n",
    "                     np.zeros(twenty)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def train_test_split(files, idx):\n",
    "    \"\"\"\n",
    "    Files tagged as 1 are categorised as training files\n",
    "    Files tagged as 0 are categorised as test files\n",
    "    \"\"\"\n",
    "    train = files[idx == 1]\n",
    "    test = files[idx == 0]\n",
    "    print(\"TRAIN SET: {0}\".format(train))\n",
    "    print(\"TEST SET: {0}\".format(test))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def generate_train_test(df):\n",
    "    top_groups = identify_top_groups(df, SIZE)\n",
    "    randomize_files(top_groups)\n",
    "    eighty, twenty, files = prepare_split(top_groups)\n",
    "    idx = generate_ids(eighty, twenty)\n",
    "    train, test = train_test_split(files, idx) \n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def sort_groups(df):\n",
    "    \"\"\"\n",
    "    Within each mixed groups (hits + noise), we need to sort\n",
    "    groups such that those with highest hits are selected first\n",
    "    \n",
    "    DataFrame --> List(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # group by groups and labels and associated counts for each label\n",
    "    grouped_df = pd.DataFrame(df.groupby(['group', 'label'])['label'].count())\n",
    "    grouped_df = grouped_df.rename(columns={'label':'count'})\n",
    "    \n",
    "    # sort groups based on highest occurance of hits\n",
    "    grouped_sorted_df = grouped_df.sort_values(grouped_df.columns.tolist())\\\n",
    "                            .sort_index(level=1, ascending=False, sort_remaining=False)\\\n",
    "                            .reset_index()\n",
    "    \n",
    "    # Obtain list of groups with highest hits based on sorted order\n",
    "    sorted_groups_list = pd.DataFrame(grouped_sorted_df.group)\n",
    "\n",
    "    # Drop duplicate groups\n",
    "    sorted_groups_list = sorted_groups_list.drop_duplicates()\n",
    "\n",
    "    # Count the occurances of groups (should only occur once)\n",
    "    sorted_groups_list['g'] = sorted_groups_list.groupby('group').cumcount()\n",
    "\n",
    "    # Make copy of dataframe\n",
    "    copy_df = df\n",
    "    \n",
    "    # Save original index positions as a column\n",
    "    copy_df_indices = copy_df.reset_index()\n",
    "    \n",
    "    # Make a count of occurances for each group\n",
    "    copy_df_indices['group_count'] = copy_df_indices.groupby('group').cumcount() \n",
    "    \n",
    "    # Merge the list of groups with the partial df to obtain corresponding full dataframe\n",
    "    copy_df = sorted_groups_list.merge(copy_df_indices)\\\n",
    "                                .set_index('index')\\\n",
    "                                .rename_axis(None)\\\n",
    "                                .drop(['group_count', 'g'], axis=1)\n",
    "    \n",
    "    # For each group, sort by labels within each group starting from 1 till 0\n",
    "    df = copy_df.groupby(['group'], sort=False)\\\n",
    "                 .apply(lambda x: x.sort_values(['label'], ascending=False))\\\n",
    "                 .reset_index(drop=True)\n",
    "    \n",
    "    return df    \n",
    "\n",
    "\n",
    "def equal_sampling(df):\n",
    "    \"\"\"\n",
    "    Equally sample points from each timeslice group.\n",
    "    Use 6550 - min number of points in hits group\n",
    "    \n",
    "    **Note** \n",
    "    Sorting values on label ensures that max number of\n",
    "    hits per group is taken. \n",
    "    \n",
    "    **For example**\n",
    "    Group 1 has 6549 noise and 600 hits. Sorting first on hits will allow\n",
    "    sample to have 600 hits and 5950 noise. \n",
    "    Without any sorting, sample would have had 6549 noise and 1 hit\n",
    "    \"\"\"    \n",
    "    POINTS = 6550\n",
    "    return df.groupby('group', sort=False)\\\n",
    "             .head(POINTS)\\\n",
    "             .reset_index(drop=True)\n",
    "\n",
    "\n",
    "def remove_groups(df):\n",
    "    \"\"\"\n",
    "    Remove groups that have less than 6550 members per timeslice\n",
    "    group\n",
    "    \"\"\"\n",
    "    POINTS = 6550\n",
    "    g = df.groupby('group')\n",
    "    \n",
    "    return g.filter(lambda x: len(x) >= POINTS)\n",
    "\n",
    "\n",
    "def sample_noise_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample noise based on specified tag\n",
    "    \"\"\"\n",
    "    if tag == \"equal\":\n",
    "        sampled_noise = equal_sampling(df)\n",
    "        equal_sampled_noise = remove_groups(sampled_noise)\n",
    "\n",
    "        return equal_sampled_noise\n",
    "    \n",
    "    \n",
    "def sample_mixed_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample mixed data based on specified tag\n",
    "    \"\"\"\n",
    "    df = sort_groups(df)\n",
    "    \n",
    "    if tag == \"equal\":\n",
    "        return equal_sampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_noise_test(df_noise, test, WRITE_NOISE_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled noise test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TEST + file_name,\n",
    "                   df_noise[df_noise.group == idx][['pos_x', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_NOISE_TEST))\n",
    "    \n",
    "def save_mixed_test(df_mixed, test, WRITE_MIXED_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled mixed test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TEST + file_name,\n",
    "                   df_mixed[df_mixed.group == idx][['pos_x', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_MIXED_TEST))\n",
    "    \n",
    "    \n",
    "def save_noise_train(sampled_df, train, WRITE_NOISE_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled noise train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_x', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_NOISE_TRAIN))\n",
    "    \n",
    "    \n",
    "def save_mixed_train(sampled_df, train, WRITE_MIXED_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled mixed train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_x', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_MIXED_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_PATH = \"../../data/simplified_data.csv\"\n",
    "WRITE_NOISE_TRAIN = \"../../data/ensemble/xzt/points/noise/train/\"\n",
    "WRITE_NOISE_TEST = \"../../data/ensemble/xzt/points/noise/test/\"\n",
    "\n",
    "WRITE_MIXED_TRAIN =  \"../../data/ensemble/xzt/points/mixed/train/\"\n",
    "WRITE_MIXED_TEST = \"../../data/ensemble/xzt/points/mixed/test/\"\n",
    "\n",
    "SIZE = 200\n",
    "\n",
    "df = read_csv(READ_PATH)\n",
    "df_noise, df_mixed = identify_groups(df)\n",
    "df_noise, df_mixed = generate_dfs(df, df_noise, df_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: [5605 1405 1101 5182 1567  532  762  669 1346 1955 5103 5678 2869 5009\n",
      " 6540 4874 5840  374 3219 1304 1639 4274  208 4989 3704    0 2272  788\n",
      " 2957 4430 5097 6117 2751 3487 1202 5511 4775 4477  474 3180 6432 1016\n",
      " 2658 1531  648 5006 1204 3403 4391 1620 5941 4640 3985 1129 4019 4671\n",
      " 3123  134 6396 1413 1481 2093 5718 3974 5977 4199 4615 4426 3355  758\n",
      " 4267 4081 5648  210 5905 6630 5491 4590 3253 1586 1681 2533 6427 3941\n",
      "  576 5038 2932  999 2956 5982 4571 4328 5149  437 6048 2587 5434 3416\n",
      " 3222 4799 4897 2872 3168 4969 3440 4870 1108 3815 5308 1151 3492 4060\n",
      " 3042 2128 1374 2385 6560 5701 6132 3763  914 3609  432 6433 3943  601\n",
      " 3925 5337 3152 4695 4900 1846 1189 6241 3968 3594  583 5510 6589 2414\n",
      "  416 4591 1325 1055 4848 5991 4796 6139 5412 3569 5578 2834 4483 1583\n",
      " 3215 3758 3352 6555  903 5922]\n",
      "TEST SET: [2527 4444 2875 1667 4179 3189  630 5067 3340  449 1729 5222 6177 3060\n",
      " 2719 2934 3507 3960 4463 5190 3792 2557 1246 1333 2621 3799  686 1391\n",
      " 6181  990  301  909 4032  347 2197  190 6436 4647 5550 6333]\n",
      "All 40 files saved successfully in ../../data/ensemble/xzt/points/noise/test/!\n",
      "All 160 files saved successfully in ../../data/ensemble/xzt/points/noise/train/!\n"
     ]
    }
   ],
   "source": [
    "####NOISE####\n",
    "train, test = generate_train_test(df_noise)\n",
    "df_train_noise = df_noise[df_noise.group.isin(train)]\n",
    "df_train_noise = sample_noise_data(\"equal\", df_train_noise)\n",
    "\n",
    "save_noise_test(df_noise, test, WRITE_NOISE_TEST)\n",
    "save_noise_train(df_train_noise, train, WRITE_NOISE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: [2517 5883 6426   36 6084 1214 1273 5866 2330 3310 3727  231 4282 5281\n",
      " 1038 2338 4565 6542 5272  411 1657 2323 5295  797 4215 5215 1496 3611\n",
      "   50 1454 6553 4793 2774 2099 2231 1653 4926 2161 2567 1813 1488 1344\n",
      " 4227 5133 2404 4562  941 2654 5886 6530  810 6221 4791  584 5621 5280\n",
      " 2642 4080 4735 3398 3094 3490 3315 3287 4854 1163 1732 5116 1637 3953\n",
      " 2795 3170 3670 3072  530  979 6038 2759 4243 1836 5422 2362 6590  845\n",
      " 4327 4417 1194 4034 5234 1172 4532 1825 3967 2374 3025 3924 6134  997\n",
      " 5114 1937 6314   55 6495 1209 5847 2821 6567 1516  809 3483 6534 6203\n",
      " 3923 3001  281 5795 1446  103 5032 1869 1276 1926 2890 5211 3252  394\n",
      "  477 1820 4943 2024  355 2098 4740 3628 1918 4347 1154 4646 4301  491\n",
      " 3700  716 4515 1599 1671 3845 1275 2021 5270 4679 6588 4428 4075 5725\n",
      "  102 5857 1184 1484 6337 4653]\n",
      "TEST SET: [1357 1658 4460  615 5812 5659 6378 2367 6493  166 4132 5747  375  249\n",
      " 4569  554 5823  831 6109 3063 1973 5219 2211 5312 1650 5010 2389 1232\n",
      " 5799  857 3514 6006 4717 2185   32 2711  988 4958 1584 1893]\n",
      "All 40 files saved successfully in ../../data/ensemble/xzt/points/mixed/test/!\n",
      "All 160 files saved successfully in ../../data/ensemble/xzt/points/mixed/train/!\n"
     ]
    }
   ],
   "source": [
    "####MIXED####\n",
    "train, test = generate_train_test(df_mixed)\n",
    "df_train_mixed = df_mixed[df_mixed.group.isin(train)]\n",
    "df_train_mixed = sample_mixed_data(\"equal\", df_train_mixed)\n",
    "\n",
    "save_mixed_test(df_mixed, test, WRITE_MIXED_TEST)\n",
    "save_mixed_train(df_train_mixed, train, WRITE_MIXED_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
