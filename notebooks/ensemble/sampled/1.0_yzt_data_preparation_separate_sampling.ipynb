{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yzt Train & Test Data Preparation\n",
    "\n",
    "Here the data is prepared such that 6550 points, ordered and hits first can be taken for train and random points can be taken for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_stats(df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    General Stats on mixed and noise groups\n",
    "    \"\"\"\n",
    "    noise_stats = df_noise.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    mixed_stats = df_mixed.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    \n",
    "    neg, pos = np.bincount(df_mixed['label'])\n",
    "    total = neg + pos\n",
    "    \n",
    "    hits = df_mixed[df_mixed.label == 1].groupby(['group', 'label'])['label']\n",
    "    noise = df_mixed[df_mixed.label == 0].groupby(['group', 'label'])['label']\n",
    "    \n",
    "    hits_count = hits.count().sort_values(ascending=False)[:SIZE]\n",
    "    noise_count = noise.count().sort_values(ascending=False)[:SIZE]\n",
    "    \n",
    "    hits_to_noise = hits_count.droplevel(level='label')/noise_count.droplevel(level='label')\n",
    "    \n",
    "    class_imbalance = df_mixed.groupby(['group', 'label'])['label'].count()[:20]\n",
    "    \n",
    "        \n",
    "    print(\"NOISE STATS: \\n{}\\n\".format(noise_stats))\n",
    "    print(\"MIXED STATS: \\n{}\\n\".format(mixed_stats))\n",
    "    \n",
    "    print(\"Mixed Groups: \\n\")\n",
    "    print(\"Examples:\\n Total: {}\\n Positive: {} ({:.2f}% of total)\\n\".format(total,\n",
    "                                                                             pos, 100 * pos / total))\n",
    "    \n",
    "    print(\"Example of class imbalance in mixed groups: \\n \".format(class_imbalance.head()))\n",
    "           \n",
    "    print(\"Hits Only (Within mixed groups):\\n\")\n",
    "    print(\"The largest hits for a group: {}\\n\".format(hits_count.max()))\n",
    "    print(\"The smallest hits for a group: {}\\n\".format(hits_count.min()))\n",
    "    print(\"The mean hits for a group: {}\\n\".format(hits_count.mean()))\n",
    "                                                                                                                                    \n",
    "    print(\"Noise Only (Within mixed groups):\\n\") \n",
    "    print(\"The largest noise for a group: {}\\n\".format(noise_count.max()))\n",
    "    print(\"The smallest noise for a group: {}\\n\".format(noise_count.min())) \n",
    "    print(\"The mean noise for a group: {}\\n\".format(noise_count.mean()))\n",
    "    print(\"Hits-Noise Ratio:\\n\") \n",
    "    print(\"The highest ratio: {:.2f}% ({})\\n\".format(hits_to_noise.max()*100,\n",
    "                                                    hits_to_noise.max()))\n",
    "    print(\"The smallest ratio: {:.2f}% ({}) \\n\".format(hits_to_noise.min()*100,\n",
    "                                                       hits_to_noise.min())) \n",
    "    print(\"The mean ratio: {:.2f}% ({})\\n\".format(hits_to_noise.mean()*100, \n",
    "                                                  hits_to_noise.mean()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot(df_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of full data in mixed groups\n",
    "    \"\"\"\n",
    "    pos_df = pd.DataFrame(df_mixed[df_mixed.label == 1], columns = df_mixed.columns)\n",
    "    neg_df = pd.DataFrame(df_mixed[df_mixed.label == 0], columns = df_mixed.columns)\n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"Positive distribution (Hits) for pos_z vs time\")\n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"Negative distribution (Noise) for pos_z vs time\")\n",
    "    \n",
    "    plt.savefig(\"../../assets/Distributon of points in Mixed Groups (posz-time)\")\n",
    "    \n",
    "\n",
    "def sampled_plot(sampled_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of equally sampled points in mixed groups\n",
    "    \"\"\"\n",
    "    list_mixed_groups = df_mixed.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    data_subset = sampled_mixed.loc[sampled_mixed['group'].isin(list_mixed_groups)]\n",
    "    pos_df = data_subset[data_subset.label == 1]\n",
    "    neg_df = data_subset[data_subset.label == 0]\n",
    "    \n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"EQUAL SAMPLING: Positive distribution (Hits) for pos_z vs time\")\n",
    "    \n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"EQUAL SAMPLING: Negative distribution (Noise) for pos_z vs time\")\n",
    "\n",
    "    plt.savefig(\"../../assets/Distributon of Equally Sampled points in Mixed Groups (posz-time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(READ_PATH):\n",
    "    \"\"\"\n",
    "    Read CSV at specified Path\n",
    "    \"\"\"\n",
    "    return pd.read_csv(READ_PATH)\n",
    "\n",
    "\n",
    "def identify_groups(df):\n",
    "    \"\"\"\n",
    "    1. Tag groups that have only noise [0]\n",
    "    2. Tag groups that have both noise and hits [0,1]\n",
    "    3. Separate noise groups and hits+noise groups\n",
    "    \"\"\"\n",
    "    # Label groups by noise and and hits\n",
    "    df_count_label_type = pd.DataFrame(df.groupby('group')['label'].unique()).reset_index()\n",
    "    \n",
    "    # Obtain groups with only hits\n",
    "    df_noise = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) == 1]\n",
    "    \n",
    "    # Obtain groups with noise && hits\n",
    "    df_mixed = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) > 1]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def generate_dfs(df, df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    Obtain full dataframe based on identified noise\n",
    "    only groups and mixed groups\n",
    "    \"\"\"\n",
    "    df_noise = df[df.group.isin(df_noise.group)]\n",
    "    df_mixed = df[df.group.isin(df_mixed.group)]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def identify_top_groups(df, SIZE):\n",
    "    \"\"\"\n",
    "    Obtain a list of the top groups to be selected as \n",
    "    per SIZE\n",
    "    \n",
    "    **Note: SIZE == 200**\n",
    "    \"\"\"\n",
    "    top_groups = df.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "    top_groups = list(top_groups.index)\n",
    "    \n",
    "    return top_groups\n",
    "\n",
    "\n",
    "def randomize_files(files):\n",
    "    \"\"\"\n",
    "    Shuffles files in a random order\n",
    "    \"\"\"\n",
    "    return shuffle(files)\n",
    "\n",
    "\n",
    "def prepare_split(files):\n",
    "    \"\"\"\n",
    "    Identifies the ratios for files to be split into\n",
    "    \n",
    "    **Note**\n",
    "    Current setting is for 80-20\n",
    "    \"\"\"\n",
    "    eighty = int(0.8 * len(files))\n",
    "    twenty = int(len(files) - eighty)\n",
    "    files = np.array(files)\n",
    "    \n",
    "    return eighty, twenty, files\n",
    "\n",
    "\n",
    "def generate_ids(eighty, twenty):\n",
    "    \"\"\"\n",
    "    Assigns 1 to 80% of the files and 0 to 20% of the files\n",
    "    \"\"\"\n",
    "    idx = np.hstack((np.ones(eighty),\n",
    "                     np.zeros(twenty)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def train_test_split(files, idx):\n",
    "    \"\"\"\n",
    "    Files tagged as 1 are categorised as training files\n",
    "    Files tagged as 0 are categorised as test files\n",
    "    \"\"\"\n",
    "    train = files[idx == 1]\n",
    "    test = files[idx == 0]\n",
    "    print(\"TRAIN SET: {0}\".format(train))\n",
    "    print(\"TEST SET: {0}\".format(test))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def generate_train_test(df):\n",
    "    top_groups = identify_top_groups(df, SIZE)\n",
    "    randomize_files(top_groups)\n",
    "    eighty, twenty, files = prepare_split(top_groups)\n",
    "    idx = generate_ids(eighty, twenty)\n",
    "    train, test = train_test_split(files, idx) \n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def sort_groups(df):\n",
    "    \"\"\"\n",
    "    Within each mixed groups (hits + noise), we need to sort\n",
    "    groups such that those with highest hits are selected first\n",
    "    \n",
    "    DataFrame --> List(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # group by groups and labels and associated counts for each label\n",
    "    grouped_df = pd.DataFrame(df.groupby(['group', 'label'])['label'].count())\n",
    "    grouped_df = grouped_df.rename(columns={'label':'count'})\n",
    "    \n",
    "    # sort groups based on highest occurance of hits\n",
    "    grouped_sorted_df = grouped_df.sort_values(grouped_df.columns.tolist())\\\n",
    "                            .sort_index(level=1, ascending=False, sort_remaining=False)\\\n",
    "                            .reset_index()\n",
    "    \n",
    "    # Obtain list of groups with highest hits based on sorted order\n",
    "    sorted_groups_list = pd.DataFrame(grouped_sorted_df.group)\n",
    "\n",
    "    # Drop duplicate groups\n",
    "    sorted_groups_list = sorted_groups_list.drop_duplicates()\n",
    "\n",
    "    # Count the occurances of groups (should only occur once)\n",
    "    sorted_groups_list['g'] = sorted_groups_list.groupby('group').cumcount()\n",
    "\n",
    "    # Make copy of dataframe\n",
    "    copy_df = df\n",
    "    \n",
    "    # Save original index positions as a column\n",
    "    copy_df_indices = copy_df.reset_index()\n",
    "    \n",
    "    # Make a count of occurances for each group\n",
    "    copy_df_indices['group_count'] = copy_df_indices.groupby('group').cumcount() \n",
    "    \n",
    "    # Merge the list of groups with the partial df to obtain corresponding full dataframe\n",
    "    copy_df = sorted_groups_list.merge(copy_df_indices)\\\n",
    "                                .set_index('index')\\\n",
    "                                .rename_axis(None)\\\n",
    "                                .drop(['group_count', 'g'], axis=1)\n",
    "    \n",
    "    # For each group, sort by labels within each group starting from 1 till 0\n",
    "    df = copy_df.groupby(['group'], sort=False)\\\n",
    "                 .apply(lambda x: x.sort_values(['label'], ascending=False))\\\n",
    "                 .reset_index(drop=True)\n",
    "    \n",
    "    return df    \n",
    "\n",
    "\n",
    "def equal_sampling(df):\n",
    "    \"\"\"\n",
    "    Equally sample points from each timeslice group.\n",
    "    Use 6550 - min number of points in hits group\n",
    "    \n",
    "    **Note** \n",
    "    Sorting values on label ensures that max number of\n",
    "    hits per group is taken. \n",
    "    \n",
    "    **For example**\n",
    "    Group 1 has 6549 noise and 600 hits. Sorting first on hits will allow\n",
    "    sample to have 600 hits and 5950 noise. \n",
    "    Without any sorting, sample would have had 6549 noise and 1 hit\n",
    "    \"\"\"    \n",
    "    POINTS = 6550\n",
    "    return df.groupby('group', sort=False)\\\n",
    "             .head(POINTS)\\\n",
    "             .reset_index(drop=True)\n",
    "\n",
    "\n",
    "def remove_groups(df):\n",
    "    \"\"\"\n",
    "    Remove groups that have less than 6550 members per timeslice\n",
    "    group\n",
    "    \"\"\"\n",
    "    POINTS = 6550\n",
    "    g = df.groupby('group')\n",
    "    \n",
    "    return g.filter(lambda x: len(x) >= POINTS)\n",
    "\n",
    "\n",
    "def sample_noise_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample noise based on specified tag\n",
    "    \"\"\"\n",
    "    if tag == \"equal\":\n",
    "        sampled_noise = equal_sampling(df)\n",
    "        equal_sampled_noise = remove_groups(sampled_noise)\n",
    "\n",
    "        return equal_sampled_noise\n",
    "    \n",
    "    \n",
    "def sample_mixed_data(tag, df):\n",
    "    \"\"\"\n",
    "    Sample mixed data based on specified tag\n",
    "    \"\"\"\n",
    "    df = sort_groups(df)\n",
    "    \n",
    "    if tag == \"equal\":\n",
    "        return equal_sampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_noise_test(df_noise, test, WRITE_NOISE_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled noise test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TEST + file_name,\n",
    "                   df_noise[df_noise.group == idx][['pos_y', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_NOISE_TEST))\n",
    "    \n",
    "def save_mixed_test(df_mixed, test, WRITE_MIXED_TEST):\n",
    "    \"\"\"\n",
    "    Save unsampled mixed test data\n",
    "    \"\"\"\n",
    "    for idx in test:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TEST + file_name,\n",
    "                   df_mixed[df_mixed.group == idx][['pos_y', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                  .format(len(test), WRITE_MIXED_TEST))\n",
    "    \n",
    "    \n",
    "def save_noise_train(sampled_df, train, WRITE_NOISE_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled noise train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_NOISE_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_y', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_NOISE_TRAIN))\n",
    "    \n",
    "    \n",
    "def save_mixed_train(sampled_df, train, WRITE_MIXED_TRAIN):\n",
    "    \"\"\"\n",
    "    Save sampled mixed train data\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx in train:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_MIXED_TRAIN + file_name,\n",
    "                   sampled_df[sampled_df.group == idx][['pos_y', 'pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\"\\\n",
    "                .format(len(train), WRITE_MIXED_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_PATH = \"../../data/simplified_data.csv\"\n",
    "WRITE_NOISE_TRAIN = \"../../data/ensemble/yzt/points/noise/train/\"\n",
    "WRITE_NOISE_TEST = \"../../data/ensemble/yzt/points/noise/test/\"\n",
    "\n",
    "WRITE_MIXED_TRAIN =  \"../../data/ensemble/yzt/points/mixed/train/\"\n",
    "WRITE_MIXED_TEST = \"../../data/ensemble/yzt/points/mixed/test/\"\n",
    "\n",
    "SIZE = 200\n",
    "\n",
    "df = read_csv(READ_PATH)\n",
    "df_noise, df_mixed = identify_groups(df)\n",
    "df_noise, df_mixed = generate_dfs(df, df_noise, df_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: [2957 6432 3440 3925 4848 3403 6427 5991 1405 2557 1955 4969 6048 1586\n",
      " 5701 3941 3189  669 4483  648 6139 1583 2587 1531  762 6630 5678 5905\n",
      " 3219 3222 1325 1729 5941 3340 5605  576 5511 1374 3974  208 3799 4989\n",
      " 6433 1567 3123 4328  449 6181 5434 3168 2875 4870 6177 2533 1151 4444\n",
      " 6241 4274 2751 6333 1391 4199 2932 2956 1055 4590  134 1346 1639 4463\n",
      "  758 1101 5006  903 5578  437 4897  210 4647 4799 4671 5982 6132 5840\n",
      " 2128 1413 5182 3152 2869 5337  583  374 4060 2934  999 3943 3060 3042\n",
      " 1304 4267 2197 3492 5308  532 2414 4615 1620 3968 6540 4900 5491 1246\n",
      " 5977 3985 1667  416 3355 4874 3594 3758 5222 2658 4430 4081 5097 3253\n",
      " 3487 2385 2719 1016 3180 3792  990 4640 3352 4477 2872 5038 1202 1189\n",
      " 1129 4571 3215 3704 2834 3609 5922 3507 4032  686 4426 2093 3815 1846\n",
      "  347  914 4695 2272  788 2621]\n",
      "TEST SET: [4019 1333  301 5412 5009 1108 4179 5103 4796    0 5067 5190 6396 6555\n",
      " 3763 3569 5149  432 5648 3960 6589  190 4775 1681 6560  630  909  601\n",
      " 4591 1204 5510 1481 4391 3416 5718 2527  474 6117 5550 6436]\n",
      "All 40 files saved successfully in ../../data/ensemble/yzt/points/noise/test/!\n",
      "All 160 files saved successfully in ../../data/ensemble/yzt/points/noise/train/!\n"
     ]
    }
   ],
   "source": [
    "####NOISE####\n",
    "train, test = generate_train_test(df_noise)\n",
    "df_train_noise = df_noise[df_noise.group.isin(train)]\n",
    "df_train_noise = sample_noise_data(\"equal\", df_train_noise)\n",
    "\n",
    "save_noise_test(df_noise, test, WRITE_NOISE_TEST)\n",
    "save_noise_train(df_train_noise, train, WRITE_NOISE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: [4428 5215   32 2362 6337 3845 3287 4132 4854 1820 4653 5659 6084 4717\n",
      " 6134 5799 2211 1214 5866 3953 5280 2231  810 1516  997 4646 1869 4515\n",
      " 4227 5857 1163 5295 1194  615   36 6567 6314  281 4075  103 5725 2404\n",
      "  831  809 6534 3063 2759 6203 2654 6378 3094 4347 1599 2323 1813  979\n",
      "  716 4958 6006 6493 5133 5219 3923 4327 3514 1344 2367 2774 4417 3611\n",
      " 6590 1209 4243 3001 2099 1836 6495 2890  530 4034  411 5886 5847 1825\n",
      " 3310  857 4282 3072 4215 6530 5281  491 4926  102 6109 5234 5116 4460\n",
      " 5312 4943 1275 5270   55 5795 2389 5812 3170 2021 6221 2374 3025 4080\n",
      " 2517 3252 2821 1671 4740 1637 2567 3670  797 1172 3490 1454 6553 2711\n",
      " 5211 6542 1038 6588 5010 1488 1918 1650 5032 1937  554  941 4569 5272\n",
      " 3628  375 1232 4793 1357 5114 4562 1893 4301 1496 2024 1584 1446 5883\n",
      " 3398 1732 3483 4791 5621 3315]\n",
      "TEST SET: [3924 5823  477 6038 3967 1653 5422 3727  355 4532 1184 1657 1273 4735\n",
      " 4679   50 2338 2185 2330 1926 1973  166  394 1658 1154 3700 2642  845\n",
      "  231 2161 1484  988 5747 4565 2795 2098 1276  584  249 6426]\n",
      "All 40 files saved successfully in ../../data/ensemble/yzt/points/mixed/test/!\n",
      "All 160 files saved successfully in ../../data/ensemble/yzt/points/mixed/train/!\n"
     ]
    }
   ],
   "source": [
    "####MIXED####\n",
    "train, test = generate_train_test(df_mixed)\n",
    "df_train_mixed = df_mixed[df_mixed.group.isin(train)]\n",
    "df_train_mixed = sample_mixed_data(\"equal\", df_train_mixed)\n",
    "\n",
    "save_mixed_test(df_mixed, test, WRITE_MIXED_TEST)\n",
    "save_mixed_train(df_train_mixed, train, WRITE_MIXED_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pos_z</th>\n",
       "      <th>time</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18334220</td>\n",
       "      <td>18334220</td>\n",
       "      <td>18334220</td>\n",
       "      <td>18334220</td>\n",
       "      <td>18334220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pos_x     pos_y     pos_z      time     group\n",
       "label                                                  \n",
       "0      18334220  18334220  18334220  18334220  18334220"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noise.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>pos_z</th>\n",
       "      <th>time</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "      <td>26996090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "      <td>489906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pos_x     pos_y     pos_z      time     group\n",
       "label                                                  \n",
       "0      26996090  26996090  26996090  26996090  26996090\n",
       "1        489906    489906    489906    489906    489906"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixed.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9151776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27485996 - 18334220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18334220 == 26996090 + 489906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489907.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26996090 /26996090 + 489906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
