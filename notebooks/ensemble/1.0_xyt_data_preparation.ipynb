{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xyt Train & Test Data Preparation\n",
    "\n",
    "Point Cloud NN requires data in the following scheme:\n",
    "\n",
    "dataset\n",
    "\n",
    "--- class1  \n",
    "\n",
    "    --- train  \n",
    "        * file.off\n",
    "        * file.off\n",
    "    \n",
    "    --- test \n",
    "        * file.off\n",
    "        * file.off\n",
    "    \n",
    "\n",
    "--- class2  \n",
    "\n",
    "    --- train \n",
    "        * file.off\n",
    "        * file.off\n",
    "    \n",
    "    --- test  \n",
    "        * file.off\n",
    "        * file.off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(READ_PATH):\n",
    "    \"\"\"\n",
    "    Read CSV at specified Path\n",
    "    \"\"\"\n",
    "    return pd.read_csv(READ_PATH)\n",
    "\n",
    "\n",
    "def identify_groups(df):\n",
    "    \"\"\"\n",
    "    1. Tag groups that have only noise [0]\n",
    "    2. Tag groups that have both noise and hits [0,1]\n",
    "    3. Separate noise groups and hits+noise groups\n",
    "    \"\"\"\n",
    "    # Label groups by noise and and hits\n",
    "    df_count_label_type = pd.DataFrame(df.groupby('group')['label'].unique()).reset_index()\n",
    "    \n",
    "    # Obtain groups with only hits\n",
    "    df_noise = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) == 1]\n",
    "    \n",
    "    # Obtain groups with noise && hits\n",
    "    df_mixed = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) > 1]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def generate_dfs(df, df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    Obtain full dataframe based on identified noise\n",
    "    only groups and mixed groups\n",
    "    \"\"\"\n",
    "    df_noise = df[df.group.isin(df_noise.group)]\n",
    "    df_mixed = df[df.group.isin(df_mixed.group)]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def print_df_stats(df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    General Stats on mixed and noise groups\n",
    "    \"\"\"\n",
    "    noise_stats = df_noise.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    mixed_stats = df_mixed.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    \n",
    "    neg, pos = np.bincount(df_mixed['label'])\n",
    "    total = neg + pos\n",
    "    \n",
    "    hits = df_mixed[df_mixed.label == 1].groupby(['group', 'label'])['label']\n",
    "    noise = df_mixed[df_mixed.label == 0].groupby(['group', 'label'])['label']\n",
    "    \n",
    "    hits_count = hits.count().sort_values(ascending=False)\n",
    "    noise_count = noise.count().sort_values(ascending=False)\n",
    "    \n",
    "    hits_to_noise = hits_count.droplevel(level='label')/noise_count.droplevel(level='label')\n",
    "    \n",
    "    class_imbalance = df_mixed.groupby(['group', 'label'])['label'].count()[:20]\n",
    "    \n",
    "        \n",
    "    print(\"NOISE STATS: \\n{}\\n\".format(noise_stats))\n",
    "    print(\"EVENTS + NOISE STATS: \\n{}\\n\".format(mixed_stats))\n",
    "    \n",
    "    print(\"Events Groups: \\n\")\n",
    "    print(\"Examples:\\n Total: {}\\n Positive: {} ({:.2f}% of total)\\n\".format(total,\n",
    "                                                                             pos, 100 * pos / total))\n",
    "    \n",
    "    print(\"Example of class imbalance in events groups: \\n \".format(class_imbalance.head()))\n",
    "           \n",
    "    print(\"Hits Only (Within events groups):\\n\")\n",
    "    print(\"The largest hits for a group: {}\\n\".format(hits_count.max()))\n",
    "    print(\"The smallest hits for a group: {}\\n\".format(hits_count.min()))\n",
    "    print(\"The mean hits for a group: {}\\n\".format(hits_count.mean()))\n",
    "                                                                                                                                    \n",
    "    print(\"Noise Only (Within mixed groups):\\n\") \n",
    "    print(\"The largest noise for a group: {}\\n\".format(noise_count.max()))\n",
    "    print(\"The smallest noise for a group: {}\\n\".format(noise_count.min())) \n",
    "    print(\"The mean noise for a group: {}\\n\".format(noise_count.mean()))\n",
    "    print(\"Hits-Noise Ratio:\\n\") \n",
    "    print(\"The highest ratio: {:.2f}% ({})\\n\".format(hits_to_noise.max()*100,\n",
    "                                                    hits_to_noise.max()))\n",
    "    print(\"The smallest ratio: {:.2f}% ({}) \\n\".format(hits_to_noise.min()*100,\n",
    "                                                       hits_to_noise.min())) \n",
    "    print(\"The mean ratio: {:.2f}% ({})\\n\".format(hits_to_noise.mean()*100, \n",
    "                                                  hits_to_noise.mean())) \n",
    "    \n",
    "#     summary_plot(df_noise, df_mixed)\n",
    "    \n",
    "\n",
    "def sort_mixed_groups(df):\n",
    "    \"\"\"\n",
    "    Within each mixed groups (hits + noise), we need to sort\n",
    "    groups such that those with highest hits are selected first\n",
    "    \n",
    "    DataFrame --> List(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # group by groups and labels and associated counts for each label\n",
    "    grouped_df = pd.DataFrame(df.groupby(['group', 'label'])['label'].count())\n",
    "    grouped_df = grouped_df.rename(columns={'label':'count'})\n",
    "    \n",
    "    # sort groups based on highest occurance of hits\n",
    "    grouped_sorted_df = grouped_df.sort_values(grouped_df.columns.tolist())\\\n",
    "                            .sort_index(level=1, ascending=False, sort_remaining=False)\\\n",
    "                            .reset_index()\n",
    "    \n",
    "    # Obtain list of groups with highest hits based on sorted order\n",
    "    sorted_groups_list = pd.DataFrame(grouped_sorted_df.group)\n",
    "    \n",
    "    # Drop duplicate groups\n",
    "    sorted_groups_list = sorted_groups_list.drop_duplicates()\n",
    "    \n",
    "    # Count the occurances of groups (should only occur once)\n",
    "    sorted_groups_list['g'] = sorted_groups_list.groupby('group').cumcount()\n",
    "    \n",
    "    # Make copy of dataframe\n",
    "    copy_df = df\n",
    "    \n",
    "    # Save original index positions as a column\n",
    "    copy_df_indices = copy_df.reset_index()\n",
    "    \n",
    "    # Make a count of occurances for each group\n",
    "    copy_df_indices['group_count'] = copy_df_indices.groupby('group').cumcount() \n",
    "    \n",
    "    # Merge the list of groups with the partial df to obtain corresponding full dataframe\n",
    "    copy_df = sorted_groups_list.merge(copy_df_indices)\\\n",
    "                                .set_index('index')\\\n",
    "                                .rename_axis(None)\\\n",
    "                                .drop(['group_count', 'g'], axis=1)\n",
    "    \n",
    "    # For each group, sort by labels within each group starting from 1 till 0\n",
    "    df = copy_df.groupby(['group'], sort=False)\\\n",
    "                 .apply(lambda x: x.sort_values(['label'], ascending=False))\\\n",
    "                 .reset_index(drop=True)\n",
    "    \n",
    "    return df    \n",
    "\n",
    "    \n",
    "def equal_sampling(df):\n",
    "    \"\"\"\n",
    "    Equally sample points from each timeslice group.\n",
    "    Use 6550 - min number of points in hits group\n",
    "    \n",
    "    **Note** \n",
    "    Sorting values on label ensures that max number of\n",
    "    hits per group is taken. \n",
    "    \n",
    "    **For example**\n",
    "    Group 1 has 6549 noise and 600 hits. Sorting first on hits will allow\n",
    "    sample to have 600 hits and 5950 noise. \n",
    "    Without any sorting, sample would have had 6549 noise and 1 hit\n",
    "    \"\"\"    \n",
    "    POINTS = 6550\n",
    "    return df.groupby('group', sort=False)\\\n",
    "             .head(POINTS)\\\n",
    "             .reset_index(drop=True)\n",
    "\n",
    "\n",
    "def remove_groups(df):\n",
    "    \"\"\"\n",
    "    Remove groups that have less than 6550 members per timeslice\n",
    "    group\n",
    "    \"\"\"\n",
    "    POINTS = 6550\n",
    "    g = df.groupby('group')\n",
    "    \n",
    "    return g.filter(lambda x: len(x) >= POINTS)\n",
    "\n",
    "\n",
    "def sample_data(tag, df_noise):\n",
    "    \"\"\"\n",
    "    Sample based on specified tag\n",
    "    \"\"\"\n",
    "    if tag == \"equal\":\n",
    "        sampled_noise = equal_sampling(df_noise)\n",
    "        equal_sampled_noise = remove_groups(sampled_noise)\n",
    "\n",
    "        return equal_sampled_noise\n",
    "    \n",
    "def save_noise(sampled_noise):\n",
    "    \"\"\"\n",
    "    Save sampled noise data\n",
    "    \"\"\"\n",
    "    list_noise_groups = sampled_noise.group.unique()[:SIZE]\n",
    "    \n",
    "    for idx in list_noise_groups:\n",
    "        file_name = \"group_\" + str(idx) + \".xyz\"\n",
    "        np.savetxt(WRITE_NOISE + file_name,\n",
    "                   sampled_noise[sampled_noise.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\".format(len(list_noise_groups), WRITE_NOISE))\n",
    "    \n",
    "    \n",
    "def save_unsampled_noise(df_noise, WRITE_NOISE):\n",
    "    \"\"\"\n",
    "    Save unsampled noise data\n",
    "    \"\"\"\n",
    "    list_noise_groups = df_noise.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "\n",
    "    list_noise_groups = list(list_noise_groups.index)\n",
    "    \n",
    "    for idx in list_noise_groups:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_NOISE + file_name,\n",
    "                   df_noise[df_noise.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\".format(len(list_noise_groups), WRITE_NOISE))\n",
    "    \n",
    "\n",
    "def sample_mixed_data(df, tag):\n",
    "    \"\"\"\n",
    "    Sample mixed data based on specified tag\n",
    "    \"\"\"\n",
    "    sorted_mixed_df = sort_mixed_groups(df)\n",
    "\n",
    "    if tag == \"equal\":\n",
    "        return equal_sampling(sorted_mixed_df)\n",
    "    \n",
    "    \n",
    "def save_mixed(sampled_mixed, WRITE_MIXED):\n",
    "    \"\"\"\n",
    "    Save mixed groups that have been sampled\n",
    "    \"\"\"\n",
    "    list_mixed_groups = sampled_mixed.group.unique()[:SIZE]\n",
    "    \n",
    "    for idx in list_mixed_groups:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_MIXED + file_name,\n",
    "                   sampled_mixed[sampled_mixed.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "\n",
    "    print(\"All {0} files saved successfully in {1}!\".format(len(list_mixed_groups),\n",
    "                                                        WRITE_MIXED))\n",
    "\n",
    "def save_unsampled_mixed(df_mixed, WRITE_MIXED):\n",
    "    \"\"\"\n",
    "    Save unsampled mixed groups\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_mixed_df = sort_mixed_groups(df_mixed)\n",
    "    list_mixed_groups = sorted_mixed_df.group.unique()[:SIZE]\n",
    "    \n",
    "    for idx in list_mixed_groups:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\" \n",
    "        np.savetxt(WRITE_MIXED + file_name,\n",
    "                   df_mixed[df_mixed.group == idx][['pos_x', 'pos_y', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\".format(len(list_mixed_groups),\n",
    "                                                            WRITE_MIXED))\n",
    "    \n",
    "def summary_plot(df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    Summary plots of class imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    df_noise['class'] = 'noise'\n",
    "    df_mixed['class'] = 'events'\n",
    "    df_old = pd.concat([df_noise, df_mixed])\n",
    "    sns.countplot(x='class', hue='label', data=df_old)\n",
    "    plt.savefig(\"../../assets/class_imbalance.png\", dpi=600, bbox_inches=\"tight\")    \n",
    "\n",
    "    \n",
    "def generate_plots(df_mixed, df_noise):\n",
    "    \"\"\"\n",
    "    Generate plots after 200 timeslices are selected\n",
    "    \"\"\"\n",
    "    sorted_mixed_df = sort_mixed_groups(df_mixed)\n",
    "    list_mixed_groups = sorted_mixed_df.group.unique()[:SIZE]\n",
    "    list_noise_groups = df_noise.groupby('group')['label']\\\n",
    "                            .count()\\\n",
    "                            .sort_values(ascending=False)[:SIZE]\n",
    "    list_noise_groups = list(list_noise_groups.index)\n",
    "    \n",
    "    df_mixed = df_mixed[df_mixed.group.isin(list_mixed_groups)]\n",
    "    df_noise = df_noise[df_noise.group.isin(list_noise_groups)]\n",
    "    \n",
    "    df_noise['class'] = 'noise'\n",
    "    df_mixed['class'] = 'events'\n",
    "    \n",
    "    df_new = pd.concat([df_noise, df_mixed])\n",
    "    \n",
    "    sns.countplot(x='class', hue='label', data=df_new)\n",
    "    plt.savefig(\"../../assets/class_imbalance_after_sampling.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    df = read_csv(READ_PATH)\n",
    "    df_noise, df_mixed = identify_groups(df)\n",
    "    \n",
    "    df_noise, df_mixed = generate_dfs(df, df_noise, df_mixed)\n",
    "\n",
    "#     print_df_stats(df_noise, df_mixed) \n",
    "    \n",
    "#     sample = input(\"Do you want to sample noise data? (y/n) \\n\")\n",
    "    \n",
    "#     if sample == \"y\":\n",
    "#         sampled_noise = sample_data(\"equal\", df_noise)\n",
    "#         save_noise(sampled_noise)\n",
    "#     else:\n",
    "    save_unsampled_noise(df_noise, WRITE_NOISE)\n",
    "        \n",
    "#     sample = input(\"Do you want to sample mixed data? (y/n) \\n\")\n",
    "    \n",
    "#     if sample == \"y\":\n",
    "#         sampled_mixed = sample_mixed_data(df_mixed, tag=\"equal\")\n",
    "#         save_mixed(sampled_mixed, WRITE_MIXED)\n",
    "#     else:\n",
    "    save_unsampled_mixed(df_mixed, WRITE_MIXED)\n",
    "    \n",
    "#     generate_plots(df_mixed, df_noise)\n",
    "    \n",
    "    return df_noise, df_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-129cb0f3c079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mSIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_mixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-d6255eef5bab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m#     print_df_stats(df_noise, df_mixed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Do you want to sample noise data? (y/n) \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Coding/Thesis/km3net/venv/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Coding/Thesis/km3net/venv/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "READ_PATH = \"../../data/simplified_data.csv\"\n",
    "WRITE_NOISE = \"../../data/ensemble/xyt/points/0/\"\n",
    "WRITE_MIXED = \"../../data/ensemble/xyt/points/1/\"\n",
    "\n",
    "SIZE = 200\n",
    "\n",
    "df_noise, df_mixed = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mixed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b020fbf0b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_mixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_mixed' is not defined"
     ]
    }
   ],
   "source": [
    "df_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
