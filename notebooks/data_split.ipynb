{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_files(files):\n",
    "    return shuffle(files)\n",
    "\n",
    "\n",
    "def prepare_split(files):\n",
    "    eighty = int(0.8 * len(files))\n",
    "    twenty = int(len(files) - eighty)\n",
    "    files = np.array(files)\n",
    "    \n",
    "    return eighty, twenty, files\n",
    "\n",
    "\n",
    "def generate_ids(eighty, twenty):\n",
    "    idx = np.hstack((np.ones(eighty),\n",
    "                     np.zeros(twenty)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def train_test_split(files, idx):\n",
    "    train = files[idx == 1]\n",
    "    test = files[idx == 0]\n",
    "    print(\"TRAIN SET: {0}\".format(train))\n",
    "    print(\"TEST SET: {0}\".format(test))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET: ['group_0_mesh.off' 'group_601_mesh.off' 'group_1846_mesh.off'\n",
      " 'group_3704_mesh.off' 'group_2533_mesh.off' 'group_3609_mesh.off'\n",
      " 'group_2128_mesh.off' 'group_5550_mesh.off' 'group_5991_mesh.off'\n",
      " 'group_5701_mesh.off' 'group_5006_mesh.off' 'group_4267_mesh.off'\n",
      " 'group_3042_mesh.off' 'group_1108_mesh.off' 'group_1667_mesh.off'\n",
      " 'group_3355_mesh.off' 'group_4274_mesh.off' 'group_1189_mesh.off'\n",
      " 'group_5097_mesh.off' 'group_4647_mesh.off' 'group_903_mesh.off'\n",
      " 'group_4444_mesh.off' 'group_4179_mesh.off' 'group_4897_mesh.off'\n",
      " 'group_5038_mesh.off' 'group_4870_mesh.off' 'group_2093_mesh.off'\n",
      " 'group_1304_mesh.off' 'group_909_mesh.off' 'train' 'group_449_mesh.off'\n",
      " 'group_4848_mesh.off' 'group_1481_mesh.off' 'group_2719_mesh.off'\n",
      " 'group_5337_mesh.off' 'group_4874_mesh.off' 'group_6427_mesh.off'\n",
      " 'group_1016_mesh.off' 'group_3594_mesh.off' 'test' 'group_3799_mesh.off']\n",
      "TEST SET: ['group_1955_mesh.off' 'group_5941_mesh.off' 'group_3763_mesh.off'\n",
      " 'group_4571_mesh.off' 'group_3569_mesh.off' 'group_3180_mesh.off'\n",
      " 'group_4989_mesh.off' 'group_762_mesh.off' 'group_5718_mesh.off'\n",
      " 'group_5190_mesh.off' 'group_5434_mesh.off']\n"
     ]
    }
   ],
   "source": [
    "PATH_MIXED = \"../data/meshes/mixed/\"\n",
    "PATH_NOISE = \"../data/meshes/noise/\"\n",
    "\n",
    "# -------> Change this!!!!\n",
    "files = os.listdir(PATH_NOISE)\n",
    "    \n",
    "if \".ipynb_checkpoints\" in files:\n",
    "    files.remove(\".ipynb_checkpoints\")\n",
    "    \n",
    "# First: Randomize data \n",
    "randomize_files(files)\n",
    "\n",
    "# Calculate Split\n",
    "eighty, twenty, files = prepare_split(files)\n",
    "\n",
    "# Generate 1s and 0s as IDs\n",
    "idx = generate_ids(eighty, twenty)\n",
    "\n",
    "# Split data \n",
    "train, test = train_test_split(files, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_0_mesh.off\n",
      "group_601_mesh.off\n",
      "group_1846_mesh.off\n",
      "group_3704_mesh.off\n",
      "group_2533_mesh.off\n",
      "group_3609_mesh.off\n",
      "group_2128_mesh.off\n",
      "group_5550_mesh.off\n",
      "group_5991_mesh.off\n",
      "group_5701_mesh.off\n",
      "group_5006_mesh.off\n",
      "group_4267_mesh.off\n",
      "group_3042_mesh.off\n",
      "group_1108_mesh.off\n",
      "group_1667_mesh.off\n",
      "group_3355_mesh.off\n",
      "group_4274_mesh.off\n",
      "group_1189_mesh.off\n",
      "group_5097_mesh.off\n",
      "group_4647_mesh.off\n",
      "group_903_mesh.off\n",
      "group_4444_mesh.off\n",
      "group_4179_mesh.off\n",
      "group_4897_mesh.off\n",
      "group_5038_mesh.off\n",
      "group_4870_mesh.off\n",
      "group_2093_mesh.off\n",
      "group_1304_mesh.off\n",
      "group_909_mesh.off\n",
      "train\n",
      "group_449_mesh.off\n",
      "group_4848_mesh.off\n",
      "group_1481_mesh.off\n",
      "group_2719_mesh.off\n",
      "group_5337_mesh.off\n",
      "group_4874_mesh.off\n",
      "group_6427_mesh.off\n",
      "group_1016_mesh.off\n",
      "group_3594_mesh.off\n",
      "test\n",
      "group_3799_mesh.off\n"
     ]
    }
   ],
   "source": [
    "for file in train:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_paths = [PATH_MIXED + \"train/\", PATH_MIXED + \"test/\"]\n",
    "dir_noise_paths = [PATH_NOISE + \"train/\", PATH_NOISE + \"test/\"]\n",
    "categories = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MIXED data\n",
    "for paths, category in zip(dir_paths, categories):\n",
    "    if not os.path.exists(paths):\n",
    "        os.makedirs(paths)\n",
    "        \n",
    "    if os.path.exists(paths):\n",
    "        for file in category:\n",
    "            file_path = PATH_MIXED + file\n",
    "            print(f'file_path: {file_path}')\n",
    "            shutil.move(file_path, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: ../data/meshes/noise/group_0_mesh.off\n",
      "file_path: ../data/meshes/noise/group_601_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1846_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3704_mesh.off\n",
      "file_path: ../data/meshes/noise/group_2533_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3609_mesh.off\n",
      "file_path: ../data/meshes/noise/group_2128_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5550_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5991_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5701_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5006_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4267_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3042_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1108_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1667_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3355_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4274_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1189_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5097_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4647_mesh.off\n",
      "file_path: ../data/meshes/noise/group_903_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4444_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4179_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4897_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5038_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4870_mesh.off\n",
      "file_path: ../data/meshes/noise/group_2093_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1304_mesh.off\n",
      "file_path: ../data/meshes/noise/group_909_mesh.off\n",
      "file_path: ../data/meshes/noise/train\n",
      "file_path: ../data/meshes/noise/group_449_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4848_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1481_mesh.off\n",
      "file_path: ../data/meshes/noise/group_2719_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5337_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4874_mesh.off\n",
      "file_path: ../data/meshes/noise/group_6427_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1016_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3594_mesh.off\n",
      "file_path: ../data/meshes/noise/test\n",
      "file_path: ../data/meshes/noise/group_3799_mesh.off\n",
      "file_path: ../data/meshes/noise/group_1955_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5941_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3763_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4571_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3569_mesh.off\n",
      "file_path: ../data/meshes/noise/group_3180_mesh.off\n",
      "file_path: ../data/meshes/noise/group_4989_mesh.off\n",
      "file_path: ../data/meshes/noise/group_762_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5718_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5190_mesh.off\n",
      "file_path: ../data/meshes/noise/group_5434_mesh.off\n"
     ]
    }
   ],
   "source": [
    "# Save NOISE data\n",
    "for paths, category in zip(dir_noise_paths, categories):\n",
    "#     print(paths, category)\n",
    "    if not os.path.exists(paths):\n",
    "        os.makedirs(paths)\n",
    "        \n",
    "    if os.path.exists(paths):\n",
    "        for noise_file in category:\n",
    "            file_path = PATH_NOISE + noise_file\n",
    "            print(f'file_path: {file_path}')\n",
    "            shutil.move(file_path, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
