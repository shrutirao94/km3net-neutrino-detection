{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xyt Train & Test Data Preparation\n",
    "\n",
    "Point Cloud NN requires data in the following scheme:\n",
    "\n",
    "dataset\n",
    "\n",
    "--- class1  \n",
    "\n",
    "    --- train  \n",
    "        * file.off\n",
    "        * file.off\n",
    "    \n",
    "    --- test \n",
    "        * file.off\n",
    "        * file.off\n",
    "    \n",
    "\n",
    "--- class2  \n",
    "\n",
    "    --- train \n",
    "        * file.off\n",
    "        * file.off\n",
    "    \n",
    "    --- test  \n",
    "        * file.off\n",
    "        * file.off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(READ_PATH):\n",
    "    \"\"\"\n",
    "    Read CSV at specified Path\n",
    "    \"\"\"\n",
    "    return pd.read_csv(READ_PATH)\n",
    "\n",
    "\n",
    "def identify_groups(df):\n",
    "    \"\"\"\n",
    "    1. Tag groups that have only noise [0]\n",
    "    2. Tag groups that have both noise and hits [0,1]\n",
    "    3. Separate noise groups and hits+noise groups\n",
    "    \"\"\"\n",
    "    # Label groups by noise and and hits\n",
    "    df_count_label_type = pd.DataFrame(df.groupby('group')['label'].unique()).reset_index()\n",
    "    \n",
    "    # Obtain groups with only hits\n",
    "    df_noise = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) == 1]\n",
    "    \n",
    "    # Obtain groups with noise && hits\n",
    "    df_mixed = df_count_label_type.loc[\n",
    "        np.array(list(map(len, df_count_label_type.label.values))) > 1]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def generate_dfs(df, df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    Obtain full dataframe based on identified noise\n",
    "    only groups and mixed groups\n",
    "    \"\"\"\n",
    "    df_noise = df[df.group.isin(df_noise.group)]\n",
    "    df_mixed = df[df.group.isin(df_mixed.group)]\n",
    "    \n",
    "    return df_noise, df_mixed\n",
    "\n",
    "\n",
    "def print_df_stats(df_noise, df_mixed):\n",
    "    \"\"\"\n",
    "    General Stats on mixed and noise groups\n",
    "    \"\"\"\n",
    "    noise_stats = df_noise.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    mixed_stats = df_mixed.groupby('group')['label']\\\n",
    "                    .count()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .describe()\n",
    "    \n",
    "    neg, pos = np.bincount(df_mixed['label'])\n",
    "    total = neg + pos\n",
    "    \n",
    "    hits = df_mixed[df_mixed.label == 1].groupby(['group', 'label'])['label']\n",
    "    noise = df_mixed[df_mixed.label == 0].groupby(['group', 'label'])['label']\n",
    "    \n",
    "    hits_count = hits.count().sort_values(ascending=False)[:SIZE]\n",
    "    noise_count = noise.count().sort_values(ascending=False)[:SIZE]\n",
    "    \n",
    "    hits_to_noise = hits_count.droplevel(level='label')/noise_count.droplevel(level='label')\n",
    "    \n",
    "    class_imbalance = df_mixed.groupby(['group', 'label'])['label'].count()[:20]\n",
    "    \n",
    "        \n",
    "    print(\"NOISE STATS: \\n{}\\n\".format(noise_stats))\n",
    "    print(\"MIXED STATS: \\n{}\\n\".format(mixed_stats))\n",
    "    \n",
    "    print(\"Mixed Groups: \\n\")\n",
    "    print(\"Examples:\\n Total: {}\\n Positive: {} ({:.2f}% of total)\\n\".format(total,\n",
    "                                                                             pos, 100 * pos / total))\n",
    "    \n",
    "    print(\"Example of class imbalance in mixed groups: \\n \".format(class_imbalance.head()))\n",
    "           \n",
    "    print(\"Hits Only (Within mixed groups):\\n\")\n",
    "    print(\"The largest hits for a group: {}\\n\".format(hits_count.max()))\n",
    "    print(\"The smallest hits for a group: {}\\n\".format(hits_count.min()))\n",
    "    print(\"The mean hits for a group: {}\\n\".format(hits_count.mean()))\n",
    "                                                                                                                                    \n",
    "    print(\"Noise Only (Within mixed groups):\\n\") \n",
    "    print(\"The largest noise for a group: {}\\n\".format(noise_count.max()))\n",
    "    print(\"The smallest noise for a group: {}\\n\".format(noise_count.min())) \n",
    "    print(\"The mean noise for a group: {}\\n\".format(noise_count.mean()))\n",
    "    print(\"Hits-Noise Ratio:\\n\") \n",
    "    print(\"The highest ratio: {:.2f}% ({})\\n\".format(hits_to_noise.max()*100,\n",
    "                                                    hits_to_noise.max()))\n",
    "    print(\"The smallest ratio: {:.2f}% ({}) \\n\".format(hits_to_noise.min()*100,\n",
    "                                                       hits_to_noise.min())) \n",
    "    print(\"The mean ratio: {:.2f}% ({})\\n\".format(hits_to_noise.mean()*100, \n",
    "                                                  hits_to_noise.mean())) \n",
    "\n",
    "def sort_mixed_groups(df):\n",
    "    \"\"\"\n",
    "    Within each mixed groups (hits + noise), we need to sort\n",
    "    groups such that those with highest hits are selected first\n",
    "    \n",
    "    DataFrame --> List(int)\n",
    "    \"\"\"\n",
    "    \n",
    "    # group by groups and labels and associated counts for each label\n",
    "    grouped_df = pd.DataFrame(df.groupby(['group', 'label'])['label'].count())\n",
    "    grouped_df = grouped_df.rename(columns={'label':'count'})\n",
    "    \n",
    "    # sort groups based on highest occurance of hits\n",
    "    grouped_sorted_df = grouped_df.sort_values(grouped_df.columns.tolist())\\\n",
    "                            .sort_index(level=1, ascending=False, sort_remaining=False)\\\n",
    "                            .reset_index()\n",
    "    \n",
    "    # Obtain list of groups with highest hits based on sorted order\n",
    "    sorted_groups_list = pd.DataFrame(grouped_sorted_df.group)\n",
    "    \n",
    "    # Drop duplicate groups\n",
    "    sorted_groups_list = sorted_groups_list.drop_duplicates()\n",
    "    \n",
    "    # Count the occurances of groups (should only occur once)\n",
    "    sorted_groups_list['g'] = sorted_groups_list.groupby('group').cumcount()\n",
    "    \n",
    "    # Make copy of dataframe\n",
    "    copy_df = df\n",
    "    \n",
    "    # Save original index positions as a column\n",
    "    copy_df_indices = copy_df.reset_index()\n",
    "    \n",
    "    # Make a count of occurances for each group\n",
    "    copy_df_indices['group_count'] = copy_df_indices.groupby('group').cumcount() \n",
    "    \n",
    "    # Merge the list of groups with the partial df to obtain corresponding full dataframe\n",
    "    copy_df = sorted_groups_list.merge(copy_df_indices)\\\n",
    "                                .set_index('index')\\\n",
    "                                .rename_axis(None)\\\n",
    "                                .drop(['group_count', 'g'], axis=1)\n",
    "    \n",
    "    # For each group, sort by labels within each group starting from 1 till 0\n",
    "    df = copy_df.groupby(['group'], sort=False)\\\n",
    "                 .apply(lambda x: x.sort_values(['label'], ascending=False))\\\n",
    "                 .reset_index(drop=True)\n",
    "    \n",
    "    return df    \n",
    "    \n",
    "    \n",
    "def save_unsampled_noise(df_noise, WRITE_NOISE):\n",
    "    \"\"\"\n",
    "    Save unsampled noise data\n",
    "    \"\"\"\n",
    "    list_noise_groups = df_noise.groupby('group')['label'].count().sort_values(ascending=False)[:SIZE]\n",
    "\n",
    "    list_noise_groups = list(list_noise_groups.index)\n",
    "    \n",
    "    for idx in list_noise_groups:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\"\n",
    "        np.savetxt(WRITE_NOISE + file_name,\n",
    "                   df_noise[df_noise.group == idx][['pos_x', 'pos_y','pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\".format(len(list_noise_groups), WRITE_NOISE))\n",
    "    \n",
    "\n",
    "def save_unsampled_mixed(df_mixed, WRITE_MIXED):\n",
    "    \"\"\"\n",
    "    Save unsampled mixed groups\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_mixed_df = sort_mixed_groups(df_mixed)\n",
    "    list_mixed_groups = sorted_mixed_df.group.unique()[:SIZE]\n",
    "    \n",
    "    for idx in list_mixed_groups:\n",
    "        file_name = \"group_\"+str(idx)+\".xyz\" \n",
    "        np.savetxt(WRITE_MIXED + file_name,\n",
    "                   df_mixed[df_mixed.group == idx][['pos_x', 'pos_y','pos_z', 'time']].values)\n",
    "    \n",
    "    print(\"All {0} files saved successfully in {1}!\".format(len(list_mixed_groups),\n",
    "                                                            WRITE_MIXED))\n",
    "    \n",
    "    \n",
    "def plot(df_mixed):\n",
    "    \"\"\"\n",
    "    Generate plots of full data in mixed groups\n",
    "    \"\"\"\n",
    "    pos_df = pd.DataFrame(df_mixed[df_mixed.label == 1], columns = df_mixed.columns)\n",
    "    neg_df = pd.DataFrame(df_mixed[df_mixed.label == 0], columns = df_mixed.columns)\n",
    "    sns.jointplot(pos_df['pos_z'], pos_df['time'],\n",
    "                  kind='hex')\n",
    "    plt.suptitle(\"Positive distribution (Hits) for pos_z vs time\")\n",
    "    sns.jointplot(neg_df['pos_z'], neg_df['time'],\n",
    "                  kind='hex')\n",
    "    _ = plt.suptitle(\"Negative distribution (Noise) for pos_z vs time\")\n",
    "    \n",
    "    plt.savefig(\"../../assets/Distributon of points in Mixed Groups (posz-time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = read_csv(READ_PATH)\n",
    "    df_noise, df_mixed = identify_groups(df)\n",
    "    \n",
    "    df_noise, df_mixed = generate_dfs(df, df_noise, df_mixed)\n",
    "\n",
    "    print_df_stats(df_noise, df_mixed) \n",
    "    \n",
    "    save_unsampled_noise(df_noise, WRITE_NOISE)\n",
    "        \n",
    "    save_unsampled_mixed(df_mixed, WRITE_MIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "READ_PATH = \"../../data/simplified_data.csv\" \n",
    "WRITE_NOISE = \"../../data/4d/noise/\"\n",
    "WRITE_MIXED = \"../../data/4d/mixed/\"\n",
    "\n",
    "SIZE = 200\n",
    "\n",
    "# df_noise, df_mixed= main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(READ_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noise, df_mixed = identify_groups(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noise, df_mixed = generate_dfs(df, df_noise, df_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 200 files saved successfully in ../../data/4d/noise/!\n"
     ]
    }
   ],
   "source": [
    "save_unsampled_noise(df_noise, WRITE_NOISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 200 files saved successfully in ../../data/4d/mixed/!\n"
     ]
    }
   ],
   "source": [
    "save_unsampled_mixed(df_mixed, WRITE_MIXED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net",
   "language": "python",
   "name": "km3net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
