\chapter{Introduction}

\ifpdf
    \graphicspath{{1_introduction/figures/PNG/}{1_introduction/figures/PDF/}{1_introduction/figures/}}
\else
    \graphicspath{{1_introduction/figures/EPS/}{1_introduction/figures/}}
\fi

Physics has accounted for many fundamental properties of the universe. Yet, several questions regarding the elementary constituents of matter remain unanswered. For instance, it is well known that when neutron stars collide, they produce supermassive stars or black holes \cite{bekenstein1973black}. However, there is not much information on what the cores of such stars or black holes comprise of. Similarly, it has also been established that majority of the universe is comprised of dark matter, with little indication as to what dark matter really constitutes \cite{halliwell1985origin}. What is however known is that all of these phenomena have one particle in common - the neutrino \cite{bekenstein1973black}. Neutrinos are elusive, weakly interacting particles that were discovered first by Pauli in the 1930s and the only known particle making up dark matter \cite{bilenky2013neutrino, roberts1992birth}. Understanding neutrinos has become increasingly significant for researchers in recent times as it represents much of the unknown universe. Experiments are being conducted to understand the mass of neutrinos, reasons for their oscillation, their ability to change forms, and the role they play in the birth and continuum of the universe \cite{gray2011cosmic}. 

With simultaneous advancement in hardware and computing power, the ability to detect and understand neutrinos has drastically increased \cite{bilenky2013neutrino, roberts1992birth, acciarri2016long, acciarri2017convolutional, albert2020antares, aiello2019sensitivity}. Large particle accelerators are typical in particle physics experiments whereby protons and anti-protons are collided at high speeds to try to recreate neutrino particles. Through this process, petabytes of data are often produced and have to be analysed for signs of tracks, rings, jets and showers associated with neutrino interactions \cite{britton2014deal}. These experiments so far have made use of physics algorithms that have worked well in detecting particles to a certain degree. However, these techniques fall short when it comes to identifying new particles or studying previously unknown behaviour that has not been defined by the algorithm parameters \cite{edelen2016neural}. Traditional algorithms are also unable to keep up with large volumes of rapidly changing, high dimensional data. Thus, reliance on such algorithms have limited the potential for new discoveries \cite{edelen2016neural}.

On the other hand, Neural Networks (NNs) have faced several cycles of hype over the past decade or so. Early attempts at incorporating NNs were often unsuccessful due to limited understanding, large computation hours, hardware limitations, and lack of powerful architectures \cite{ahmed1974discrete}. Early applications that were developed were highly sensitive to errors and data quality \cite{ahmed1974discrete}. Due to these reasons, Neural Networks were not a favoured solution. But, recent advances in computing led to better storage of data, faster execution times and improved error handling. These factors directly contributed to enabling real-time processing of data. Also, since storage of large datasets was now possible, networks could be trained with larger datasets. Additionally, general theoretical research was advanced to address the concept of NNs being a black-box. Advances in computational theory led to development of powerful learning algorithms, optimisation techniques and robust architectures \cite{bottou2010large}. These factors combined led to new interest in application of NNs to complicated problems, including those in particle physics \cite{edelen2016neural}.

\section{Background} 
In order to understand the motivation behind the work done by this thesis and ongoing research, it is essential to understand the fundamental properties of neutrinos. It is also important to examine some significant existing applications of Neural Networks in working detectors. These can help identify scope for improvement for this thesis and for future research.

\subsection{Neutrinos}
% What are neutrinos & how are they produced
Neutrinos are fundamental particles of the universe and quite different in nature from other commonly known particles. They carry no charge, are extremely small in mass and travel through matter undetected \cite{bilenky2013neutrino}. Neutrinos come in three types (flavours) and can change between types and masses \cite{bilenky2013neutrino}. On Earth, neutrinos are produced by nuclear reactors, natural radioactive changes in the atmosphere and particle accelerators. The Sun produces neutrinos via nuclear fission that occurs in its core. They are also generated from the births, deaths and collisions of stars and supernovae explosions \cite{roberts1992birth}. 

% Why are they hard to detect
Detecting neutrinos are extremely hard because they rarely interact. Around a trillion neutrinos pass through the Earth every second yet, approximately only one neutrino reacts with matter on Earth, once a day \cite{abi2018dune, acciarri2016long}.  A neutrino travelling near the nucleus of an atom emits weak bosons (W and Z type) \cite{bahcall1989neutrino}. These in turn react with the nucleus of another atom to produce a multitude of particles, including charged particles which can be detected. However, the probability of the weak bosons hitting a nucleus of another atom is extremely small. This is because weak bosons have a very short lifetime of $1 \times 10^{-27}$ seconds and travel a very short distance of less than $0.001$ of the size of a proton \cite{bahcall1989neutrino, adamson2008study, puccini2018bosons}. These two reasons make it very hard for charged particles to be produced and in turn for neutrinos to be detected. 

% How do you detect neutrinos
\label{sec:intro-detection-of-neutrinos}
There are a few ways of detecting neutrinos, with under-water detectors being most popular. In water, neutrino particles travel undisturbed and may travel faster than light in that medium. They may react with matter particles in water and create a charged \textit{lepton} that produces a light known as \textit{Cherenkov light}. These flashes of light are detected by photomultiplier (PMT) tubes that can infer direction, energy and flavour of the neutrino \cite{adamson2008study}. \textit{Super Kamiokande} is a water based detector that uses \textit{Cherenkov light} to detect neutrinos \cite{tanaka2020search}. \textit{IceCube} is another experiment located in the South Pole that uses a cubic kilometre of ice embedded with PMT tubes to detect neutrino events \cite{albert2020antares}. \textit{MiniBooNE} detector uses pure mineral oil that allows low energy muons and protons, invisible in water, to be detected \cite{aguilar2017dark}.

% Why are they important
Neutrinos are important because understanding their origin can help resolve many physics unknowns. Neutrinos could be used to probe and examine matter that present radiation cannot pass through. Since they travel through space practically unaffected, physicists believe that neutrinos can help learn about galactic cores and supernovae. 


\subsection{Neural Networks in Neutrino Physics}
Neural Networks were first acknowledged in physics around 1988, in the field of particle physics \cite{denby1999neural}. Particle physics comprises the study of the fundamental building blocks of nature. It largely involves low-level pattern recognition and physics process determination. According to Denby (1999), low-level pattern recognition tasks include finding tracks made by particles and process determination encompasses obtaining properties such as spatial topology and energy emissions of particles. Studies of such processes require work to be done either in real-time or offline. Denby (1999) described particle physics processes to be characterised by large magnitudes of background noise with small, rarer occurrences of real events at any given point in time \cite{denby1999neural}. 

Denby (1999) found Neural Networks in particle physics that have been used in both real-time and offline applications. Overall, NNs have had challenges being recognised as a statistical tool within the community of particle research. The main challenge in particle physics lies in the fact that such experiments often have to deal with new and unknown phenomena. NNs in such instances have to be developed based on unknown, and guessed parameters. Models trained on such parameters then further reflect these unknowns and inaccuracies \cite{denby1999neural}. 

Despite these accepted fallacies, there are a few large-scale detector experiments that have incorporated Neural Networks. \textit{Fermilab} has a muon trigger that applies low-level pattern recognition techniques \cite{adamson2008study}. \textit{Fermilab} also uses NNs to analyse proton-anti-proton collisions and measures top-quarks and lepto-quarks \cite{adamson2008study}. The \textit{Hera} accelerator has a prototype experiment that studies momentum from colliding particles \cite{voss1994electron} and a secondary experiment called \textit{ZEUS} that uses a form of feedforward network to identify deeply inelastic neutral current events \cite{abramowicz1995neural}. The \textit{CMS} experiment at the Large Hadron Collider (LHC) uses a neural network based trigger to identify electrons from protons \cite{chatrchyan2010performance}. 

\section{KM3NeT}
\label{sec:intro-km3net}
KM3NeT (Cubic Kilometre Neutrino Telescope) is a next generation neutrino telescope project, currently being constructed under the Mediterranean Sea \footnote{https://www.km3net.org/}. The research unit comprises two main telescopes - the ARCA (Astroparticle Research with Cosmics in the Abyss) and the ORCA (Oscillation Research with Cosmics in the Abyss) \cite{km3net_2017}. The ARCA telescope is to be used for extraterrestrial neutrino particles originating from the likes of supernovae or colliding stars \cite{km3net_2017}. The ORCA telescope will be used to examine neutrinos travelling through the Earth's atmosphere \cite{km3net_2017}. KM3NeT is another example of the underwater detectors discussed in Section \ref{sec:intro-detection-of-neutrinos}, and relies on optical sensors to detect \textit{Cherenkov light} \cite{km3net_2017}. These highly sensitive photomultiplier tubes also acquire a significant amount of noise generated by other background factors, mainly Potassium-40 decay. The detector therefore records all photon particles as hits and solutions are in place to try and isolate relevant hits from noise hits. 

\subsection{Event Triggers}
\label{sec:intro-trigger}
Data acquisition for the offshore KM3NeT detectors is based on a preset threshold, whereby all analogue signals that exceed the threshold are sent to shore. This is known as the level-zero (L0) filter. Next, event based level-one (L1) trigger is employed to filter out relevant events. Specifically, the occurrence of two or more L0 hits within a certain time and spatial distance are considered significant for L1 \cite{km3net_2017}. 

\subsection{GPU Pipeline}
A separate GPU-based data processing pipeline was proposed as a viable solution to the event-based triggers by Karas (2019). The pipeline comprises of three components. The first component of the pipeline implements hits correlation based on closeness of hits in time and space, given a threshold. The second phase of the pipeline uses the correlation from the previous component to cluster related hits together. The final phase of the pipeline then classifies communities into significant and insignificant ones, based on the presence of neutrino events \cite{karas_2019}.
 
\section{Research Questions}
\label{sec:intro-research-questions}
Typically, particle physics research relies on building physics-derived algorithms to detect neutrinos. Previously described event triggers and the GPU pipeline for the KM3NeT are two such examples (Sec: \ref{sec:intro-km3net}). While these algorithms are physics driven, they may fall short when trying to capture complex information from imbalanced, skewed data. This could be due to three main reasons:
\begin{enumerate}
    \item Often, physics algorithms make use of theoretical parameters and criterion that may not be optimised across varied datasets.
    \item Algorithms designed to work on smaller, lower dimensional data may not be able to model increasingly higher dimensional data without suffering from information loss.
    \item Several physics algorithms are highly customised and specific to the problem or data at hand, lacking in ability to be generalised \cite{denby1999neural}. 
\end{enumerate}

Examination of literature on the topic has shown popularity of Convolutional Neural Networks (CNNs) for neutrino research. This also faces drawbacks, mainly from information loss and high compute times. Converting detector data to images and learning to detect neutrinos from them will lead to loss of information that may have been useful. It is imperative to understand if existing methodologies such as physics-based triggers and CNNs can be replaced by new models and data representations. 
Point clouds are the simplest representation of 3D geometric objects and could be one such means to represent neutrino data in a novel manner. PointNet, a point cloud specific architecture could be used to train on such data. The following research questions were formulated to address the feasibility of using PointNet for neutrino identification amidst background noise:

\begin{description}
    \item[\textbf{RQ1.0}] \textit{Can PointNet, a geometric neural network architecture be trained to identify timeslices that contain neutrino event hits from timeslices that contain only background noise?} \\
    The KM3NeT detector gathers large volumes of data in real-time and sends it onshore in chunks of time (timeslices) \cite{km3net_2017}. It would be computationally infeasible to store all of this data when most of it may be irrelevant to research. Therefore, an effective method is required to identify timeslices that contain neutrino hits so that only they may be saved and the rest gets discarded. 
    
    \item[\textbf{RQ1.1}] \textit{Can PointNet achieve a Recall score of greater than 0.9 for identifying timeslices with event hits?} \\
    KM3NeT stakeholders defined 90\% recall score for the model, which is the ability of the algorithm to learn from the data. To provide valuable contributions, PointNet would have to score 90\% or higher for Recall.
    
    \item[\textbf{RQ2.0}] \textit{Can the KM3NeT dataset be effectively represented using 3D meshes?} \\
    PointNet typically learns from 3D meshes while the KM3NeT data comprises of \texttt{x, y, z} coordinates, \texttt{time} and metadata. If these attributes can be modelled to form a surface-based 3D mesh, it could serve as a suitable training data for PointNet as a 3D mesh stores more information about geometry than just 3D coordinates.
    
    \item[\textbf{RQ2.1}] \textit{Which meshing algorithm would be most suitable for representing the data?}  \\
    The dataset is challenging as it does not contain any discerning features. Event hits are characterised by how close they occur in time and space, compared to noise hits. Yet this closeness is not very prominent. Conversion of points to 3D meshes will result transformation of data. It is essential to ensure that the transformation is such that much of the valuable information regarding event hits is maintained, if not enhanced. An ideal algorithm would allow minute differences amongst event hits to stand out more than noise.
  
    \item[\textbf{RQ3.0}] \textit{Can PointNet be extended to obtain energy properties from neutrino events?} \\
    Inferring energy from neutrino events can help identify and study the processes that formed it. PointNet is a classification specific architecture but as it learns from both local and global structure of point clouds, it may be able solve other tasks related to point cloud recognition including regression \cite{qi2017pointnet}.
\end{description}


\section{Research Outcomes}
With research in particle physics turning to AI, a rigorous assessment of state-of-the-art networks is required to identify those best for the task at hand. This thesis aims to provide an in-depth investigation of one such state-of-the-art neural network - PointNet.  This thesis contributes to the current state of knowledge by assessing the potential of 3D Neural Networks for research in neutrinos. In order to achieve this goal, an ensemble of data from the KM3NeT ORCA detectors comprising of neutrino hits and noise are examined. Noise from the data is minimised using feature engineering,  converted to 3D meshes and trained with PointNet. The thesis also briefly explores the validity of PointNet with 3D and 4D coordinate data. Finally, the thesis lays the foundation for energy inference for KM3NeT data using non-linear regression techniques. At present, there are no known studies that use 3D deep learning to identify neutrinos amidst background noise. Moreover, no known studies attempt to represent neutrino data as 3D meshes. 

Results from this thesis can not only be used by the KM3NeT project, but also by physicists interested in applying their own data to PointNet. It could also be used by deep learning experts to understand the gaps between what particle physics needs and what Neural Networks can deliver, and work on developing more streamlined solutions for the community. 

The thesis first addresses concepts relevant to 3D point-set based learning and PointNet architecture in Chapter \ref{sec:concepts}. Next, Chapter \ref{sec:exploration} describes data generation and insights gained from dataset exploration. Chapter \ref{sec:pipeline} discusses individual components of the pipeline, Chapter \ref{sec:evaluation} evaluates them and Chapter \ref{sec:results} analyses obtained results. Chapter \ref{sec:additional} summarises additional research on an alternative PointNet pipeline with 3D and 4D coordinate data. This Chapter also briefly discusses introductory work on energy inference using regression techniques. The thesis discusses limitations and recommendations in Chapter  \ref{sec:limitations} and concludes by re-addressing the research questions in Chapter \ref{sec:conclusion}. 

\let\cleardoublepage\clearpage