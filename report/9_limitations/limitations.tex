\chapter{Limitations and Recommendations}
\label{sec:limitations}
The thesis was able to successfully conclude on the role of PointNet and point-based learning for neutrino detection. However, a few key drawbacks need to be addressed as part of future work. 

Despite feature engineering, PointNet was unable to accurately classify the edge cases where timeslices had very few event hits. This was identified to be due to the loss of information at the feature engineering step involving the surface based reconstruction technique (Section \ref{sec:evaluation}). Surface based techniques like the Poisson Reconstruction make use of statistical assumptions about the underlying point cloud model \cite{rakotosaona2020pointcleannet}. These may not be reliable or available in largely unordered clouds like the KM3NeT data. An alternate would be to use a more sophisticated algorithm such as PointCleanNet - a deep learning method that classifies and discards outlier samples \cite{rakotosaona2020pointcleannet}. The approach is considered to be efficient and robust to varying amounts of noise and outliers within large densely-sampled point clouds \cite{rakotosaona2020pointcleannet}.

The Surface Poisson Reconstruction algorithm also requires several parameter specifications. Often, these parameters are arbitrary and depend on the specific dataset being used \cite{kazhdan2006poisson}. There is no way to ensure that the parameters used in this thesis may work well on a different version of the dataset. This lack of generalisability is a limiting factor of the Surface Poisson Reconstruction algorithm.

Another drawback of PointNet is that it is reliant on feature engineering to learn from the data. But given the complicated, irregular geometry of the KM3NeT data, it is unlikely that the network will be able to learn without additional features. This is since PointNet requires equal number of points to be randomly sampled per point cloud while training \cite{qi2017pointnet}. The random sampling of points does not guarantee that sufficient event hits will be picked up, considering that they are very infrequently occurring compared to noise. PointNet2 is a next generation improvement over PointNet \cite{qi2017pointnet++}. It learns hierarchical features similar to Convolutional Neural Networks and observes non-uniform densities in natural point clouds \cite{qi2017pointnet++}. Therefore, PointNet2 does not require equal, random sampling from every cloud. This could be a recommended alternative to PointNet pipeline. 

PointNet was deemed unsuitable for regression as its architecture was primarily developed for classification. The thesis alternatively conducted research into energy inference using non-linear regression techniques. However, these experiments are preliminary. Results showed that they were partial towards predicting lower energy values, even for high energy events. The bias could be addressed through different parameters or by using boosting methods \cite{dietterich1995overfitting}. 

Additional testing would also be required to validate the energy predictions obtained. Only 3D coordinates and time were used for regressing energy values, therefore the predictions are only derived from these attributes. Research on energy inference use techniques such as Maximum Likelihood Estimation (MLE) to estimate various parameters. These parameters are then used to train decision trees \cite{abbasi2011measurement}. Some studies also address uncertainties arising from DOM sensitivity, water properties, simulation and statistical uncertainties \cite{abbasi2011measurement, hieronymus2020reconstruction, d2018flavor}. The drawback of these solutions is the significant reliance on a-priori information which is what the thesis attempted to correct.  

In terms of performance, the overall execution time for the pipeline from preprocessing to evaluation was around 3 minutes. This is not ideal in real-time processing pipelines. However, long execution times are a known fallacy of deep learning models that employ complicated algorithms. Moreover, the pre-processing pipeline was evaluated on the CPU with only two cores. Improvements to the execution time could be obtained by porting the pre-processing pipeline to the GPU. Also, significant speedups could be obtained by parallelising the pre-processing of the three datasets. 